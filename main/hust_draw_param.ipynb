{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-31T06:31:31.618731Z",
     "start_time": "2025-03-31T06:31:28.547107Z"
    }
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision.models import resnet18\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset,TensorDataset,DataLoader,random_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from d2l import torch as d2l\n",
    "import random\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import grad\n",
    "import torch.nn.init as init\n",
    "d2l.use_svg_display()\n",
    "%matplotlib inline\n",
    "import math"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "a2792227eb45e88e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T06:33:52.007101Z",
     "start_time": "2025-03-31T06:33:51.885696Z"
    }
   },
   "source": [
    "def smooth_data(sequence, window_size):\n",
    "    \"\"\"数据平滑\"\"\"\n",
    "    if window_size < 1:\n",
    "        raise ValueError(\"窗口大小必须大于等于1\")\n",
    "    # 初始化平滑后的数据列表\n",
    "    smoothed_sequence = []\n",
    "    # 计算窗口内的平均值\n",
    "    for i in range(len(sequence)):\n",
    "        # 计算窗口的起始和结束索引\n",
    "        start_index = max(0, i - window_size + 1)\n",
    "        end_index = i + 1\n",
    "        # 计算窗口内的数据平均值\n",
    "        window_average = sum(sequence[start_index:end_index]) / (end_index - start_index)\n",
    "        # 将平均值添加到平滑后的数据列表中\n",
    "        smoothed_sequence.append(window_average)\n",
    "    return smoothed_sequence\n",
    "def add_row_index_to_array(arr):\n",
    "    \"\"\"\n",
    "    在输入数组的每一行的第一个元素加上行号，并扩展数组维度。\n",
    "    \n",
    "    参数:\n",
    "    arr (np.ndarray): 形状为 (n, 6) 的输入数组。\n",
    "    \n",
    "    返回:\n",
    "    np.ndarray: 形状为 (n, 7) 的数组。\n",
    "    \"\"\"\n",
    "    # 检查输入数组形状是否为 (n, 6)\n",
    "    if arr.shape[1] != 10:\n",
    "        raise ValueError(\"输入数组必须是形状为 (n, 6) 的数组。\")\n",
    "\n",
    "    # 创建一个新数组，其形状为 (n, 7)，初始化为输入数组\n",
    "    new_arr = np.zeros((arr.shape[0], 11))\n",
    "    new_arr[:, 1:] = arr  # 将输入数组的数据复制到新数组的后面六个列\n",
    "    # 在新数组的每一行的第一个元素加上行号\n",
    "    new_arr[:, 0] = np.arange(arr.shape[0])\n",
    "    return new_arr\n",
    "def make_sequences(text, window_size):\n",
    "    \"\"\"用容量作为文本序列text,window是窗口的大小\"\"\"\n",
    "    x, y = [],[]\n",
    "    for i in range(len(text) - window_size):\n",
    "        sequence = text[i:i+window_size]\n",
    "        target = text[i+window_size]\n",
    "\n",
    "        x.append(sequence)\n",
    "        y.append(target)\n",
    "    return np.array(x), np.array(y)\n",
    "def drop_outlier(array,count,bins):\n",
    "    \"\"\"离群值提取--用3sigma方法\"\"\"\n",
    "    index = []\n",
    "    range_n = np.arange(1,count,bins)\n",
    "    for i in range_n[:-1]:\n",
    "        array_lim = array[i:i+bins]\n",
    "        sigma = np.std(array_lim)\n",
    "        mean = np.mean(array_lim)\n",
    "        th_max,th_min = mean + sigma*2, mean - sigma*2\n",
    "        idx = np.where((array_lim < th_max) & (array_lim > th_min))\n",
    "        idx = idx[0] + i\n",
    "        index.extend(list(idx))\n",
    "    return np.array(index)\n",
    "def clean_data(array_figs,array_labels):\n",
    "    index_keep=drop_outlier(array_labels,len(array_labels),35)\n",
    "    array_figs,array_labels=array_figs[index_keep],array_labels[index_keep]\n",
    "    array_figs,array_labels=array_figs[drop_outlier(array_labels,len(array_labels),10)],array_labels[drop_outlier(array_labels,len(array_labels),10)]\n",
    "    return array_figs,array_labels\n",
    "Battery_list = ['1-1', '1-2', '1-3', '1-4','1-5','1-6','1-7','1-8']\n",
    "data_root='../data/HUST_data/all_path/'\n",
    "for name in Battery_list[5:6]:\n",
    "    path=data_root+name+'.npz'\n",
    "    arrays=np.load(path)\n",
    "    features,SOHs=clean_data(arrays['array1'],arrays['array2'])\n",
    "    # print(features.shape)\n",
    "    # print(SOHs.shape)\n",
    "    plt.plot(SOHs)\n",
    "    plt.xlabel('Cycle')\n",
    "    plt.ylabel('SOH')\n",
    "    # print(features[1][0])\n",
    "# plt.show()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"414.46375pt\" height=\"314.64767pt\" viewBox=\"0 0 414.46375 314.64767\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n <metadata>\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2025-03-31T14:33:51.978874</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.7.2, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 314.64767 \nL 414.46375 314.64767 \nL 414.46375 0 \nL 0 0 \nz\n\" style=\"fill: #ffffff\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 50.14375 277.09142 \nL 407.26375 277.09142 \nL 407.26375 10.97942 \nL 50.14375 10.97942 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path id=\"mffe10a0e0e\" d=\"M 0 0 \nL 0 3.5 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#mffe10a0e0e\" x=\"66.376477\" y=\"277.09142\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(63.195227 291.689858) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use xlink:href=\"#mffe10a0e0e\" x=\"135.8213\" y=\"277.09142\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 200 -->\n      <g transform=\"translate(126.27755 291.689858) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use xlink:href=\"#mffe10a0e0e\" x=\"205.266122\" y=\"277.09142\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 400 -->\n      <g transform=\"translate(195.722372 291.689858) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \nL 825 1625 \nL 2419 1625 \nL 2419 4116 \nz\nM 2253 4666 \nL 3047 4666 \nL 3047 1625 \nL 3713 1625 \nL 3713 1100 \nL 3047 1100 \nL 3047 0 \nL 2419 0 \nL 2419 1100 \nL 313 1100 \nL 313 1709 \nL 2253 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-34\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use xlink:href=\"#mffe10a0e0e\" x=\"274.710945\" y=\"277.09142\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 600 -->\n      <g transform=\"translate(265.167195 291.689858) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \nQ 1688 2584 1439 2293 \nQ 1191 2003 1191 1497 \nQ 1191 994 1439 701 \nQ 1688 409 2113 409 \nQ 2538 409 2786 701 \nQ 3034 994 3034 1497 \nQ 3034 2003 2786 2293 \nQ 2538 2584 2113 2584 \nz\nM 3366 4563 \nL 3366 3988 \nQ 3128 4100 2886 4159 \nQ 2644 4219 2406 4219 \nQ 1781 4219 1451 3797 \nQ 1122 3375 1075 2522 \nQ 1259 2794 1537 2939 \nQ 1816 3084 2150 3084 \nQ 2853 3084 3261 2657 \nQ 3669 2231 3669 1497 \nQ 3669 778 3244 343 \nQ 2819 -91 2113 -91 \nQ 1303 -91 875 529 \nQ 447 1150 447 2328 \nQ 447 3434 972 4092 \nQ 1497 4750 2381 4750 \nQ 2619 4750 2861 4703 \nQ 3103 4656 3366 4563 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-36\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use xlink:href=\"#mffe10a0e0e\" x=\"344.155768\" y=\"277.09142\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 800 -->\n      <g transform=\"translate(334.612018 291.689858) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-38\" d=\"M 2034 2216 \nQ 1584 2216 1326 1975 \nQ 1069 1734 1069 1313 \nQ 1069 891 1326 650 \nQ 1584 409 2034 409 \nQ 2484 409 2743 651 \nQ 3003 894 3003 1313 \nQ 3003 1734 2745 1975 \nQ 2488 2216 2034 2216 \nz\nM 1403 2484 \nQ 997 2584 770 2862 \nQ 544 3141 544 3541 \nQ 544 4100 942 4425 \nQ 1341 4750 2034 4750 \nQ 2731 4750 3128 4425 \nQ 3525 4100 3525 3541 \nQ 3525 3141 3298 2862 \nQ 3072 2584 2669 2484 \nQ 3125 2378 3379 2068 \nQ 3634 1759 3634 1313 \nQ 3634 634 3220 271 \nQ 2806 -91 2034 -91 \nQ 1263 -91 848 271 \nQ 434 634 434 1313 \nQ 434 1759 690 2068 \nQ 947 2378 1403 2484 \nz\nM 1172 3481 \nQ 1172 3119 1398 2916 \nQ 1625 2713 2034 2713 \nQ 2441 2713 2670 2916 \nQ 2900 3119 2900 3481 \nQ 2900 3844 2670 4047 \nQ 2441 4250 2034 4250 \nQ 1625 4250 1398 4047 \nQ 1172 3844 1172 3481 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-38\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_6\">\n     <!-- Cycle -->\n     <g transform=\"translate(215.038125 305.367983) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-43\" d=\"M 4122 4306 \nL 4122 3641 \nQ 3803 3938 3442 4084 \nQ 3081 4231 2675 4231 \nQ 1875 4231 1450 3742 \nQ 1025 3253 1025 2328 \nQ 1025 1406 1450 917 \nQ 1875 428 2675 428 \nQ 3081 428 3442 575 \nQ 3803 722 4122 1019 \nL 4122 359 \nQ 3791 134 3420 21 \nQ 3050 -91 2638 -91 \nQ 1578 -91 968 557 \nQ 359 1206 359 2328 \nQ 359 3453 968 4101 \nQ 1578 4750 2638 4750 \nQ 3056 4750 3426 4639 \nQ 3797 4528 4122 4306 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-79\" d=\"M 2059 -325 \nQ 1816 -950 1584 -1140 \nQ 1353 -1331 966 -1331 \nL 506 -1331 \nL 506 -850 \nL 844 -850 \nQ 1081 -850 1212 -737 \nQ 1344 -625 1503 -206 \nL 1606 56 \nL 191 3500 \nL 800 3500 \nL 1894 763 \nL 2988 3500 \nL 3597 3500 \nL 2059 -325 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-63\" d=\"M 3122 3366 \nL 3122 2828 \nQ 2878 2963 2633 3030 \nQ 2388 3097 2138 3097 \nQ 1578 3097 1268 2742 \nQ 959 2388 959 1747 \nQ 959 1106 1268 751 \nQ 1578 397 2138 397 \nQ 2388 397 2633 464 \nQ 2878 531 3122 666 \nL 3122 134 \nQ 2881 22 2623 -34 \nQ 2366 -91 2075 -91 \nQ 1284 -91 818 406 \nQ 353 903 353 1747 \nQ 353 2603 823 3093 \nQ 1294 3584 2113 3584 \nQ 2378 3584 2631 3529 \nQ 2884 3475 3122 3366 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \nL 1178 4863 \nL 1178 0 \nL 603 0 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \nL 3597 1613 \nL 953 1613 \nQ 991 1019 1311 708 \nQ 1631 397 2203 397 \nQ 2534 397 2845 478 \nQ 3156 559 3463 722 \nL 3463 178 \nQ 3153 47 2828 -22 \nQ 2503 -91 2169 -91 \nQ 1331 -91 842 396 \nQ 353 884 353 1716 \nQ 353 2575 817 3079 \nQ 1281 3584 2069 3584 \nQ 2775 3584 3186 3129 \nQ 3597 2675 3597 1894 \nz\nM 3022 2063 \nQ 3016 2534 2758 2815 \nQ 2500 3097 2075 3097 \nQ 1594 3097 1305 2825 \nQ 1016 2553 972 2059 \nL 3022 2063 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-43\"/>\n      <use xlink:href=\"#DejaVuSans-79\" x=\"69.824219\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"129.003906\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"183.984375\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"211.767578\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_6\">\n      <defs>\n       <path id=\"mc2dce4b59b\" d=\"M 0 0 \nL -3.5 0 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#mc2dce4b59b\" x=\"50.14375\" y=\"251.882696\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 0.75 -->\n      <g transform=\"translate(20.878125 255.681915) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \nL 1344 794 \nL 1344 0 \nL 684 0 \nL 684 794 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"DejaVuSans-37\" d=\"M 525 4666 \nL 3525 4666 \nL 3525 4397 \nL 1831 0 \nL 1172 0 \nL 2766 4134 \nL 525 4134 \nL 525 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \nL 3169 4666 \nL 3169 4134 \nL 1269 4134 \nL 1269 2991 \nQ 1406 3038 1543 3061 \nQ 1681 3084 1819 3084 \nQ 2600 3084 3056 2656 \nQ 3513 2228 3513 1497 \nQ 3513 744 3044 326 \nQ 2575 -91 1722 -91 \nQ 1428 -91 1123 -41 \nQ 819 9 494 109 \nL 494 744 \nQ 775 591 1075 516 \nQ 1375 441 1709 441 \nQ 2250 441 2565 725 \nQ 2881 1009 2881 1497 \nQ 2881 1984 2565 2268 \nQ 2250 2553 1709 2553 \nQ 1456 2553 1204 2497 \nQ 953 2441 691 2322 \nL 691 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-37\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_7\">\n      <g>\n       <use xlink:href=\"#mc2dce4b59b\" x=\"50.14375\" y=\"203.706001\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 0.80 -->\n      <g transform=\"translate(20.878125 207.50522) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-38\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_8\">\n      <g>\n       <use xlink:href=\"#mc2dce4b59b\" x=\"50.14375\" y=\"155.529305\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 0.85 -->\n      <g transform=\"translate(20.878125 159.328524) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-38\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_9\">\n      <g>\n       <use xlink:href=\"#mc2dce4b59b\" x=\"50.14375\" y=\"107.35261\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 0.90 -->\n      <g transform=\"translate(20.878125 111.151829) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-39\" d=\"M 703 97 \nL 703 672 \nQ 941 559 1184 500 \nQ 1428 441 1663 441 \nQ 2288 441 2617 861 \nQ 2947 1281 2994 2138 \nQ 2813 1869 2534 1725 \nQ 2256 1581 1919 1581 \nQ 1219 1581 811 2004 \nQ 403 2428 403 3163 \nQ 403 3881 828 4315 \nQ 1253 4750 1959 4750 \nQ 2769 4750 3195 4129 \nQ 3622 3509 3622 2328 \nQ 3622 1225 3098 567 \nQ 2575 -91 1691 -91 \nQ 1453 -91 1209 -44 \nQ 966 3 703 97 \nz\nM 1959 2075 \nQ 2384 2075 2632 2365 \nQ 2881 2656 2881 3163 \nQ 2881 3666 2632 3958 \nQ 2384 4250 1959 4250 \nQ 1534 4250 1286 3958 \nQ 1038 3666 1038 3163 \nQ 1038 2656 1286 2365 \nQ 1534 2075 1959 2075 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-39\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_10\">\n      <g>\n       <use xlink:href=\"#mc2dce4b59b\" x=\"50.14375\" y=\"59.175914\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 0.95 -->\n      <g transform=\"translate(20.878125 62.975133) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-39\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_11\">\n      <g>\n       <use xlink:href=\"#mc2dce4b59b\" x=\"50.14375\" y=\"10.999219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 1.00 -->\n      <g transform=\"translate(20.878125 14.798438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-31\" d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_13\">\n     <!-- SOH -->\n     <g transform=\"translate(14.798438 154.905733) rotate(-90) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-53\" d=\"M 3425 4513 \nL 3425 3897 \nQ 3066 4069 2747 4153 \nQ 2428 4238 2131 4238 \nQ 1616 4238 1336 4038 \nQ 1056 3838 1056 3469 \nQ 1056 3159 1242 3001 \nQ 1428 2844 1947 2747 \nL 2328 2669 \nQ 3034 2534 3370 2195 \nQ 3706 1856 3706 1288 \nQ 3706 609 3251 259 \nQ 2797 -91 1919 -91 \nQ 1588 -91 1214 -16 \nQ 841 59 441 206 \nL 441 856 \nQ 825 641 1194 531 \nQ 1563 422 1919 422 \nQ 2459 422 2753 634 \nQ 3047 847 3047 1241 \nQ 3047 1584 2836 1778 \nQ 2625 1972 2144 2069 \nL 1759 2144 \nQ 1053 2284 737 2584 \nQ 422 2884 422 3419 \nQ 422 4038 858 4394 \nQ 1294 4750 2059 4750 \nQ 2388 4750 2728 4690 \nQ 3069 4631 3425 4513 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-4f\" d=\"M 2522 4238 \nQ 1834 4238 1429 3725 \nQ 1025 3213 1025 2328 \nQ 1025 1447 1429 934 \nQ 1834 422 2522 422 \nQ 3209 422 3611 934 \nQ 4013 1447 4013 2328 \nQ 4013 3213 3611 3725 \nQ 3209 4238 2522 4238 \nz\nM 2522 4750 \nQ 3503 4750 4090 4092 \nQ 4678 3434 4678 2328 \nQ 4678 1225 4090 567 \nQ 3503 -91 2522 -91 \nQ 1538 -91 948 565 \nQ 359 1222 359 2328 \nQ 359 3434 948 4092 \nQ 1538 4750 2522 4750 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-48\" d=\"M 628 4666 \nL 1259 4666 \nL 1259 2753 \nL 3553 2753 \nL 3553 4666 \nL 4184 4666 \nL 4184 0 \nL 3553 0 \nL 3553 2222 \nL 1259 2222 \nL 1259 0 \nL 628 0 \nL 628 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-53\"/>\n      <use xlink:href=\"#DejaVuSans-4f\" x=\"63.476562\"/>\n      <use xlink:href=\"#DejaVuSans-48\" x=\"142.1875\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_12\">\n    <path d=\"M 66.376477 23.07542 \nL 66.723701 23.547266 \nL 67.070925 23.545212 \nL 67.41815 24.055304 \nL 67.765374 24.108032 \nL 68.459822 25.003559 \nL 68.807046 25.0441 \nL 69.501494 26.022255 \nL 69.848718 26.002402 \nL 70.195943 26.488291 \nL 70.543167 26.588277 \nL 70.890391 27.098809 \nL 71.584839 27.099092 \nL 71.932063 27.581807 \nL 72.279287 27.6178 \nL 72.626511 28.134226 \nL 72.973735 28.083241 \nL 73.32096 28.571482 \nL 74.015408 28.670703 \nL 74.362632 29.188716 \nL 74.709856 29.102688 \nL 75.05708 29.600324 \nL 75.751528 29.630393 \nL 76.098752 30.156385 \nL 76.445977 30.088763 \nL 76.793201 30.618467 \nL 77.140425 30.619587 \nL 77.487649 31.136778 \nL 78.182097 31.127652 \nL 78.529321 31.601397 \nL 79.223769 32.028933 \nL 79.570994 32.063522 \nL 79.918218 32.48828 \nL 80.265442 32.596018 \nL 80.612666 32.556567 \nL 80.95989 33.078676 \nL 81.654338 33.092691 \nL 82.001562 33.53621 \nL 82.348786 33.54783 \nL 82.696011 34.095898 \nL 83.043235 34.047861 \nL 83.390459 34.447268 \nL 84.084907 35.459332 \nL 84.432131 35.384952 \nL 84.779355 35.931447 \nL 85.126579 36.001917 \nL 85.473803 35.914854 \nL 85.821028 36.416103 \nL 86.168252 36.45143 \nL 86.515476 36.371282 \nL 87.209924 36.518442 \nL 87.557148 36.981928 \nL 87.904372 36.972589 \nL 88.251596 37.474207 \nL 88.59882 37.405906 \nL 89.293269 37.484339 \nL 89.640493 37.889754 \nL 89.987717 37.895281 \nL 90.334941 38.327832 \nL 91.029389 38.331715 \nL 91.376613 38.879146 \nL 92.418286 38.828232 \nL 92.76551 39.349221 \nL 93.459958 39.328858 \nL 93.807182 39.796 \nL 94.50163 39.84809 \nL 94.848855 40.309762 \nL 95.196079 40.37948 \nL 95.890527 40.384511 \nL 96.237751 40.852502 \nL 96.584975 40.790847 \nL 96.932199 41.258994 \nL 97.973872 41.255466 \nL 98.321096 41.743962 \nL 99.362768 41.755596 \nL 99.709992 42.314803 \nL 100.057216 42.358235 \nL 100.40444 42.25635 \nL 100.751664 42.299258 \nL 101.098889 42.716293 \nL 102.140561 42.768114 \nL 102.487785 43.193779 \nL 102.835009 43.265098 \nL 103.529457 43.23996 \nL 103.876681 43.272722 \nL 104.57113 44.13441 \nL 105.265578 44.142062 \nL 105.960026 44.183312 \nL 106.30725 44.613214 \nL 107.348923 44.650284 \nL 107.696147 45.180738 \nL 108.737819 45.162459 \nL 109.085043 45.636459 \nL 110.47394 45.662603 \nL 110.821164 46.071306 \nL 111.515612 46.122985 \nL 111.862836 47.072345 \nL 112.557284 46.987904 \nL 112.904508 47.521632 \nL 113.251732 47.522738 \nL 113.598957 48.053858 \nL 114.293405 48.045725 \nL 114.640629 48.577554 \nL 115.682301 48.528893 \nL 116.029525 49.029987 \nL 116.723974 49.06639 \nL 117.418422 49.166504 \nL 117.765646 49.518781 \nL 118.460094 49.623698 \nL 118.807318 49.586713 \nL 119.154542 50.038962 \nL 119.501767 50.07025 \nL 119.848991 49.936425 \nL 120.196215 50.061479 \nL 120.543439 50.539305 \nL 121.932335 50.495915 \nL 122.279559 50.964714 \nL 122.626784 51.073614 \nL 122.974008 51.394658 \nL 123.321232 51.474197 \nL 123.668456 52.001393 \nL 124.362904 51.935146 \nL 125.404576 51.967426 \nL 125.751801 52.519576 \nL 126.793473 52.550326 \nL 127.487921 52.56879 \nL 127.835145 52.589989 \nL 128.182369 53.10871 \nL 128.529593 52.85037 \nL 128.876818 53.312878 \nL 129.224042 53.024652 \nL 129.571266 52.908298 \nL 129.91849 53.246404 \nL 130.265714 53.298027 \nL 130.612938 54.09191 \nL 131.307386 54.122645 \nL 131.65461 54.653001 \nL 132.349059 54.532836 \nL 133.043507 54.573094 \nL 133.390731 55.106071 \nL 133.737955 55.07756 \nL 134.085179 56.380926 \nL 134.432403 56.47275 \nL 134.779627 56.921767 \nL 135.126852 56.91267 \nL 135.474076 57.500331 \nL 136.168524 57.407798 \nL 136.515748 57.914858 \nL 137.55742 57.934186 \nL 137.904645 58.440225 \nL 138.599093 58.441529 \nL 138.946317 58.891397 \nL 139.640765 58.862489 \nL 139.987989 59.311634 \nL 140.682437 59.3352 \nL 141.029662 59.812742 \nL 142.418558 59.824036 \nL 142.765782 60.587268 \nL 143.113006 60.388741 \nL 143.46023 60.342942 \nL 144.154679 61.288334 \nL 144.849127 61.303398 \nL 145.196351 61.79735 \nL 145.890799 61.746903 \nL 146.238023 61.805172 \nL 146.585247 62.292591 \nL 147.279696 62.23598 \nL 147.62692 62.715478 \nL 148.668592 62.78864 \nL 149.015816 63.236056 \nL 149.36304 63.263292 \nL 149.710264 63.150665 \nL 150.057488 63.184986 \nL 150.404713 63.687695 \nL 151.099161 63.798154 \nL 151.446385 63.757711 \nL 151.793609 64.260024 \nL 152.488057 64.218802 \nL 152.835281 64.725011 \nL 153.182505 64.703203 \nL 153.52973 65.119246 \nL 154.571402 65.100924 \nL 154.918626 65.566223 \nL 155.613074 65.692099 \nL 155.960298 65.603888 \nL 156.307522 65.669625 \nL 156.654747 66.117764 \nL 157.001971 66.068748 \nL 157.696419 66.111812 \nL 158.043643 66.700748 \nL 158.738091 66.624441 \nL 159.085315 67.125605 \nL 159.779764 67.079367 \nL 160.126988 67.145132 \nL 160.474212 67.620662 \nL 161.16866 67.549272 \nL 161.515884 68.055439 \nL 162.557557 68.018256 \nL 162.904781 68.552281 \nL 163.599229 68.449801 \nL 163.946453 68.55085 \nL 164.640901 69.49219 \nL 165.682574 69.530932 \nL 166.029798 69.478317 \nL 166.377022 69.967607 \nL 166.724246 70.062152 \nL 167.07147 69.944934 \nL 167.418694 70.393031 \nL 167.765918 71.347237 \nL 168.460366 71.406087 \nL 168.807591 71.897049 \nL 169.502039 71.912282 \nL 169.849263 73.275121 \nL 170.543711 73.263501 \nL 170.890935 73.739712 \nL 171.932608 73.784107 \nL 172.279832 74.239232 \nL 172.97428 74.258532 \nL 173.321504 74.741658 \nL 174.015952 74.713176 \nL 174.363176 74.808741 \nL 175.057625 75.736505 \nL 175.752073 75.712019 \nL 176.099297 76.229876 \nL 176.793745 76.150239 \nL 177.140969 76.676683 \nL 178.87709 76.700093 \nL 179.224314 77.247963 \nL 180.265986 77.246872 \nL 180.61321 77.736389 \nL 181.654883 77.828865 \nL 182.002107 78.297607 \nL 183.043779 78.286115 \nL 183.391003 78.6795 \nL 183.738227 78.816117 \nL 184.085452 78.795187 \nL 184.432676 79.236978 \nL 185.474348 79.225457 \nL 185.821572 79.72203 \nL 186.863244 79.760007 \nL 187.210469 80.263141 \nL 187.904917 80.279026 \nL 188.252141 80.2735 \nL 188.599365 80.721313 \nL 189.293813 80.705442 \nL 189.641037 81.243606 \nL 190.68271 81.205459 \nL 191.029934 81.738224 \nL 191.724382 81.721474 \nL 192.071606 82.184832 \nL 192.766054 82.129936 \nL 193.113278 82.62352 \nL 194.154951 82.642876 \nL 194.502175 83.117245 \nL 195.196623 83.119243 \nL 195.543847 83.614428 \nL 196.58552 83.648068 \nL 196.932744 84.156743 \nL 197.627192 84.119461 \nL 197.974416 84.594424 \nL 198.668864 84.5676 \nL 199.016088 85.070507 \nL 199.363312 85.919371 \nL 200.057761 85.984626 \nL 200.752209 86.056767 \nL 201.099433 86.518907 \nL 201.446657 86.506536 \nL 201.793881 87.017861 \nL 202.835554 87.070886 \nL 203.182778 87.538538 \nL 203.877226 87.548556 \nL 204.22445 88.008698 \nL 205.266122 88.052442 \nL 205.613346 88.484667 \nL 205.960571 89.334481 \nL 206.307795 89.884165 \nL 207.002243 89.911089 \nL 207.349467 90.437533 \nL 208.391139 90.471174 \nL 209.085588 91.401262 \nL 209.432812 91.381211 \nL 209.780036 92.331181 \nL 210.12726 92.218044 \nL 210.474484 92.756718 \nL 211.168932 92.729766 \nL 211.516156 93.191593 \nL 212.210605 93.311532 \nL 212.557829 93.753053 \nL 213.252277 93.74397 \nL 213.599501 93.728269 \nL 213.946725 94.232806 \nL 214.641173 94.209794 \nL 214.988398 94.721685 \nL 215.682846 94.755864 \nL 216.03007 95.199171 \nL 216.377294 95.24001 \nL 216.724518 95.735507 \nL 217.071742 95.60708 \nL 217.76619 95.673795 \nL 218.113415 96.204675 \nL 218.460639 96.173485 \nL 218.807863 96.645643 \nL 219.502311 96.698414 \nL 219.849535 97.188738 \nL 220.543983 97.116795 \nL 220.891207 98.105138 \nL 221.585656 98.083642 \nL 221.93288 98.577083 \nL 222.627328 98.528791 \nL 222.974552 99.101502 \nL 223.669 99.096344 \nL 224.016224 99.612869 \nL 224.710673 99.584557 \nL 225.405121 100.537927 \nL 225.752345 100.585851 \nL 226.099569 101.082354 \nL 226.794017 101.024964 \nL 227.141241 101.539732 \nL 227.83569 101.541078 \nL 228.182914 102.026004 \nL 228.530138 102.050362 \nL 228.877362 102.550734 \nL 229.57181 102.554304 \nL 229.919034 103.030614 \nL 230.613483 102.996903 \nL 230.960707 103.530787 \nL 231.307931 103.521845 \nL 231.655155 103.995434 \nL 232.349603 103.896964 \nL 232.696827 104.49239 \nL 233.391276 104.513065 \nL 233.7385 104.981156 \nL 234.085724 104.980703 \nL 234.432948 105.466365 \nL 235.127396 105.439399 \nL 235.47462 105.954705 \nL 235.821844 105.917097 \nL 236.169068 106.422201 \nL 236.863517 106.474121 \nL 237.210741 106.945358 \nL 237.557965 106.91543 \nL 237.905189 107.369577 \nL 238.252413 107.374466 \nL 238.599637 107.864762 \nL 238.946861 109.362177 \nL 239.294085 109.326354 \nL 239.64131 109.81383 \nL 239.988534 109.785348 \nL 240.335758 110.239707 \nL 240.682982 110.24291 \nL 241.030206 110.80009 \nL 241.37743 110.774088 \nL 241.724654 111.276783 \nL 242.071878 111.289026 \nL 242.419102 111.755926 \nL 243.113551 111.76705 \nL 243.460775 112.322728 \nL 243.807999 112.289938 \nL 244.155223 112.756513 \nL 244.502447 112.773985 \nL 244.849671 113.201563 \nL 245.196895 113.27556 \nL 245.544119 113.21732 \nL 245.891344 113.732938 \nL 246.238568 113.675803 \nL 246.585792 114.215696 \nL 246.933016 114.193023 \nL 247.28024 114.692374 \nL 247.627464 114.60242 \nL 247.974688 115.104223 \nL 248.669136 115.09871 \nL 249.016361 115.657393 \nL 249.363585 115.647572 \nL 249.710809 116.104285 \nL 250.058033 116.088144 \nL 250.405257 116.565092 \nL 250.752481 116.55547 \nL 251.099705 117.076728 \nL 251.794154 117.095192 \nL 252.141378 117.551706 \nL 252.488602 117.5244 \nL 252.835826 118.054926 \nL 253.18305 118.136901 \nL 253.530274 118.532369 \nL 253.877498 118.55993 \nL 254.224722 119.042135 \nL 254.919171 119.094707 \nL 255.266395 119.591281 \nL 255.613619 119.590317 \nL 255.960843 120.022585 \nL 256.308067 120.050543 \nL 256.655291 120.54621 \nL 257.349739 120.582217 \nL 258.044188 121.511427 \nL 258.391412 121.508876 \nL 258.738636 121.932855 \nL 259.433084 121.97589 \nL 259.780308 122.484537 \nL 260.127532 122.444775 \nL 260.474756 122.925293 \nL 260.82198 122.950445 \nL 261.169205 123.485151 \nL 261.516429 123.496034 \nL 261.863653 123.971678 \nL 262.558101 123.93295 \nL 262.905325 125.353406 \nL 263.252549 125.884172 \nL 263.599773 125.905229 \nL 263.946997 126.368106 \nL 264.294222 126.391544 \nL 264.641446 126.852719 \nL 264.98867 126.832073 \nL 265.683118 127.794824 \nL 266.030342 127.799061 \nL 266.377566 128.295153 \nL 267.072014 128.23772 \nL 267.419239 128.779993 \nL 267.766463 128.757122 \nL 268.113687 129.266775 \nL 268.460911 129.276354 \nL 268.808135 129.752735 \nL 269.155359 129.703053 \nL 269.502583 130.195121 \nL 269.849807 130.26746 \nL 270.197031 130.616407 \nL 270.544256 130.720021 \nL 270.89148 131.249909 \nL 271.238704 131.233712 \nL 271.585928 131.748721 \nL 271.933152 131.751385 \nL 272.280376 132.237444 \nL 272.6276 132.151458 \nL 272.974824 132.206042 \nL 273.322048 132.604826 \nL 273.669273 132.634499 \nL 275.058169 134.697454 \nL 275.405393 134.719234 \nL 275.752617 135.179177 \nL 276.099841 135.184009 \nL 276.447066 135.758931 \nL 276.79429 135.698522 \nL 277.141514 136.177298 \nL 277.488738 136.17802 \nL 277.835962 136.557971 \nL 278.183186 137.122322 \nL 278.53041 136.961545 \nL 278.877634 137.525116 \nL 279.224858 137.50053 \nL 279.919307 138.480725 \nL 280.266531 138.400818 \nL 280.613755 138.884142 \nL 281.308203 138.937777 \nL 281.655427 139.420095 \nL 282.002651 141.931346 \nL 282.349875 141.928554 \nL 282.6971 143.787966 \nL 283.044324 144.301615 \nL 283.391548 144.277497 \nL 283.738772 144.763258 \nL 284.085996 144.774113 \nL 284.43322 145.267214 \nL 284.780444 145.239355 \nL 285.127668 145.757794 \nL 285.474892 145.7588 \nL 286.169341 146.725476 \nL 286.863789 146.684297 \nL 287.558237 147.741523 \nL 287.905461 147.712062 \nL 288.252685 148.215267 \nL 288.599909 148.194097 \nL 288.947134 148.649534 \nL 289.294358 148.653317 \nL 289.988806 149.661031 \nL 290.33603 149.599985 \nL 290.683254 150.100725 \nL 291.030478 150.127691 \nL 291.377702 150.569751 \nL 291.724926 150.62272 \nL 292.072151 151.106483 \nL 292.419375 151.120951 \nL 292.766599 151.577819 \nL 293.113823 151.566341 \nL 293.461047 152.028877 \nL 293.808271 152.008826 \nL 294.502719 153.021032 \nL 294.849943 153.007117 \nL 295.197168 153.497597 \nL 295.544392 153.496619 \nL 295.891616 154.005719 \nL 296.23884 154.034202 \nL 296.586064 154.545923 \nL 296.933288 154.500394 \nL 297.627736 155.510885 \nL 297.974961 155.481708 \nL 298.322185 156.003718 \nL 298.669409 156.001819 \nL 299.016633 156.506668 \nL 299.363857 156.471228 \nL 299.711081 156.922087 \nL 300.058305 156.961098 \nL 300.405529 157.397037 \nL 300.752753 157.47486 \nL 301.447202 158.429521 \nL 301.794426 158.388965 \nL 302.488874 159.374176 \nL 302.836098 159.396991 \nL 303.183322 159.866824 \nL 303.530546 159.849976 \nL 303.87777 160.339237 \nL 304.224995 160.369732 \nL 304.919443 161.352393 \nL 305.266667 161.356403 \nL 305.961115 162.381688 \nL 306.308339 162.423576 \nL 306.655563 165.256665 \nL 307.002787 165.751481 \nL 307.350012 165.864788 \nL 308.04446 166.70991 \nL 308.391684 166.711781 \nL 309.086132 167.673951 \nL 309.433356 167.731483 \nL 309.78058 168.176249 \nL 310.127804 168.181507 \nL 310.475029 171.577727 \nL 311.169477 172.518741 \nL 311.516701 172.477944 \nL 312.211149 173.432633 \nL 312.558373 173.484667 \nL 312.905597 173.94203 \nL 313.252821 173.998599 \nL 313.94727 174.99407 \nL 314.294494 174.995898 \nL 314.988942 175.976744 \nL 315.336166 175.929656 \nL 315.68339 176.46072 \nL 316.030614 176.448435 \nL 316.725063 177.404583 \nL 317.072287 177.435233 \nL 317.766735 178.386648 \nL 318.113959 178.385019 \nL 318.461183 179.88001 \nL 318.808407 179.852619 \nL 319.85008 181.3085 \nL 320.197304 181.308557 \nL 321.238976 182.773833 \nL 321.5862 182.767315 \nL 322.280648 183.760306 \nL 322.627873 183.753107 \nL 323.322321 184.725183 \nL 323.669545 184.685279 \nL 325.75289 187.693641 \nL 326.100114 188.132867 \nL 326.447338 188.116911 \nL 327.141786 189.097779 \nL 327.48901 189.078763 \nL 327.836234 189.580232 \nL 328.183458 189.596485 \nL 329.225131 191.007978 \nL 329.572355 191.373943 \nL 329.919579 191.495348 \nL 330.266803 191.999417 \nL 330.614027 191.955723 \nL 331.308475 192.971904 \nL 331.655699 193.003773 \nL 332.697372 194.501535 \nL 333.044596 194.459123 \nL 333.739044 195.458441 \nL 334.086268 195.445695 \nL 335.475165 197.328863 \nL 335.822389 197.330117 \nL 336.516837 198.286612 \nL 336.864061 198.293032 \nL 337.558509 199.230524 \nL 337.905733 199.244333 \nL 338.600182 200.215778 \nL 338.947406 200.238422 \nL 339.641854 201.21504 \nL 339.989078 201.244705 \nL 341.03075 202.74207 \nL 341.377975 203.701123 \nL 342.072423 204.660141 \nL 342.419647 204.705026 \nL 343.808543 206.554837 \nL 344.155768 206.546335 \nL 345.19744 207.979395 \nL 345.544664 207.994011 \nL 346.586336 209.4604 \nL 346.93356 209.458282 \nL 347.628009 210.47391 \nL 347.975233 210.433595 \nL 348.669681 211.484862 \nL 349.016905 211.449237 \nL 350.405802 213.432329 \nL 350.753026 215.416107 \nL 351.10025 215.853264 \nL 351.447474 215.883022 \nL 352.141922 216.833339 \nL 352.489146 216.834664 \nL 353.530819 218.281122 \nL 353.878043 218.302349 \nL 354.225267 221.205269 \nL 354.572491 221.191694 \nL 356.655836 224.168768 \nL 357.00306 224.191512 \nL 357.350284 224.665327 \nL 357.697508 226.052716 \nL 358.391956 227.059835 \nL 358.73918 228.493313 \nL 359.086404 228.977785 \nL 359.433628 228.995725 \nL 360.475301 230.44406 \nL 360.822525 230.468412 \nL 361.864197 231.930294 \nL 362.211421 231.922494 \nL 362.558645 233.363347 \nL 362.90587 233.410535 \nL 363.253094 234.350706 \nL 364.294766 235.318934 \nL 364.989214 236.309268 \nL 365.336438 236.301935 \nL 366.725335 238.239107 \nL 367.072559 238.218106 \nL 368.114231 239.70461 \nL 368.461455 239.661036 \nL 369.503128 241.168086 \nL 369.850352 241.154632 \nL 370.892024 242.61171 \nL 371.239248 242.623465 \nL 372.628145 244.584981 \nL 372.975369 246.015221 \nL 373.669817 246.982854 \nL 374.017041 246.946344 \nL 375.405938 248.945909 \nL 375.753162 248.909562 \nL 376.44761 249.914633 \nL 376.794834 249.923185 \nL 378.183731 251.865954 \nL 378.530955 251.86103 \nL 379.572627 253.321857 \nL 379.919851 253.28072 \nL 380.961523 254.771347 \nL 381.308748 254.772056 \nL 382.35042 256.213497 \nL 382.697644 256.217543 \nL 383.739316 257.66986 \nL 384.08654 257.66488 \nL 385.128213 259.12013 \nL 385.475437 259.135406 \nL 386.517109 260.620478 \nL 386.864333 260.601625 \nL 387.558782 261.576924 \nL 387.906006 261.571327 \nL 388.947678 263.030821 \nL 389.294902 263.070888 \nL 390.336575 264.484683 \nL 390.683799 264.484414 \nL 391.031023 264.99542 \nL 391.031023 264.99542 \n\" clip-path=\"url(#p674a6a1f67)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 50.14375 277.09142 \nL 50.14375 10.97942 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 407.26375 277.09142 \nL 407.26375 10.97942 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 50.14375 277.09142 \nL 407.26375 277.09142 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 50.14375 10.97942 \nL 407.26375 10.97942 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p674a6a1f67\">\n   <rect x=\"50.14375\" y=\"10.97942\" width=\"357.12\" height=\"266.112\"/>\n  </clipPath>\n </defs>\n</svg>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "id": "2179174a577f8eb8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T06:34:10.446113Z",
     "start_time": "2025-03-31T06:34:10.337857Z"
    }
   },
   "source": [
    "def setup_seed(seed):\n",
    "    \"\"\"set random seed\"\"\"\n",
    "    np.random.seed(seed)  # Numpy module.\n",
    "    random.seed(seed)  # Python random module.\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    torch.manual_seed(seed) \n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "\n",
    "def evaluation(y_test, y_predict):\n",
    "    mse = mean_squared_error(y_test, y_predict)\n",
    "    rmse = sqrt(mean_squared_error(y_test, y_predict))\n",
    "    return rmse\n",
    "def get_data():\n",
    "    \"\"\"获取训练集，测试集，验证集\"\"\"\n",
    "    train_list = Battery_list\n",
    "    train_data=[]\n",
    "    for b_n in train_list:\n",
    "        path = '../data/HUST_data/all_path/' + b_n + '.npz'\n",
    "        arrays = np.load(path)\n",
    "        a,b=clean_data(arrays['array1'],arrays['array2'])\n",
    "        a=add_row_index_to_array(a)\n",
    "        train_data.append([a,b])\n",
    "    train_features=np.concatenate((train_data[0][0],train_data[5][0],train_data[2][0],train_data[3][0],train_data[7][0]),axis=0)\n",
    "    train_labls=np.concatenate((train_data[0][1],train_data[5][1],train_data[2][1],train_data[3][1],train_data[7][1]),axis=0)\n",
    "    train_valid_features=torch.from_numpy(train_features).float()\n",
    "    train_valid_labels=torch.from_numpy(train_labls).float()\n",
    "    dataset=TensorDataset(train_valid_features,train_valid_labels)\n",
    "    # 确定训练集和验证集的大小\n",
    "    train_size = int(0.001 * len(dataset))  # 80%的训练集\n",
    "    val_size = len(dataset) - train_size   # 剩余的20%作为验证集\n",
    "    # 随机分割数据集\n",
    "    train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "    # 创建DataLoader\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "    test_5_data,test_6_data,test_7_data,test_8_data=[train_data[7][0],train_data[7][1]],[train_data[6][0],train_data[6][1]],[train_data[4][0],train_data[4][1]],[train_data[2][0],train_data[2][1]]\n",
    "    return train_loader, val_loader, test_5_data,test_6_data,test_7_data,test_8_data\n",
    "\n",
    "a,b,_,_,_,_=get_data()\n",
    "for x,y in b:\n",
    "    print(x.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n",
      "torch.Size([32, 11])\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "id": "2c0abaf3d831e1fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T06:34:10.943214Z",
     "start_time": "2025-03-31T06:34:10.912701Z"
    }
   },
   "source": [
    "# class MultiHeadAttention(nn.Module):\n",
    "#     def __init__(self, input_dim=17, output_dim=12, num_heads=4, head_dim=24, dropout=0):\n",
    "#         \"\"\"用多头注意力进行解码\"\"\"\n",
    "#         \"\"\"\n",
    "#         多头注意力模块。\n",
    "#         :param input_dim: 输入特征维度\n",
    "#         :param output_dim: 输出特征维度\n",
    "#         :param num_heads: 注意力头的数量\n",
    "#         :param head_dim: 每个注意力头的维度\n",
    "#         :param dropout: Dropout 概率\n",
    "#         \"\"\"\n",
    "#         super(MultiHeadAttention, self).__init__()\n",
    "#         self.input_dim = input_dim-1\n",
    "#         self.output_dim = output_dim-1\n",
    "#         self.num_heads = num_heads\n",
    "#         self.head_dim = head_dim\n",
    "#         self.dropout = dropout\n",
    "#         # 线性变换层，将输入映射到 Q, K, V\n",
    "#         self.query = nn.Linear(input_dim-1, num_heads * head_dim)\n",
    "#         self.key = nn.Linear(input_dim-1, num_heads * head_dim)\n",
    "#         self.value = nn.Linear(input_dim-1, num_heads * head_dim)\n",
    "#         # 输出线性层\n",
    "#         self.fc_out = nn.Linear(num_heads * head_dim, output_dim-1)\n",
    "#         # Dropout 层\n",
    "#         self.dropout_layer = nn.Dropout(dropout)\n",
    "#     def forward(self, x):\n",
    "#         \"\"\"\n",
    "#         前向传播。\n",
    "#         :param x: 输入张量，形状为 (batch_size, input_dim)\n",
    "#         :return: 输出张量，形状为 (batch_size, output_dim)\n",
    "#         \"\"\"\n",
    "#         batch_size = x.size(0)\n",
    "#         x_t=x[:,0].unsqueeze(1)\n",
    "#         x=x[:,1:]\n",
    "#         # 线性变换，得到 Q, K, V\n",
    "#         Q = self.query(x).view(batch_size, -1, self.num_heads, self.head_dim).transpose(1, 2)  # (batch_size, num_heads, seq_len, head_dim)\n",
    "#         K = self.key(x).view(batch_size, -1, self.num_heads, self.head_dim).transpose(1, 2)    # (batch_size, num_heads, seq_len, head_dim)\n",
    "#         V = self.value(x).view(batch_size, -1, self.num_heads, self.head_dim).transpose(1, 2)  # (batch_size, num_heads, seq_len, head_dim)\n",
    "#         # 计算注意力分数\n",
    "#         scores = torch.matmul(Q, K.transpose(-2, -1)) / torch.sqrt(torch.tensor(self.head_dim, dtype=torch.float32))  # (batch_size, num_heads, seq_len, seq_len)\n",
    "#         attention_weights = F.softmax(scores, dim=-1)  # (batch_size, num_heads, seq_len, seq_len)\n",
    "#         attention_weights = self.dropout_layer(attention_weights)\n",
    "#         # 计算加权和\n",
    "#         attention_output = torch.matmul(attention_weights, V)  # (batch_size, num_heads, seq_len, head_dim)\n",
    "#         # 拼接多头输出\n",
    "#         attention_output = attention_output.transpose(1, 2).contiguous().view(batch_size, -1, self.num_heads * self.head_dim)  # (batch_size, seq_len, num_heads * head_dim)\n",
    "#         # 通过线性层映射到输出维度\n",
    "#         output = self.fc_out(attention_output)  # (batch_size, seq_len, output_dim)\n",
    "#         output=torch.cat((x_t,output.squeeze(1)),dim=-1)\n",
    "#         return output  # (batch_size, output_dim)\n",
    "# \"\"\"--------------------------------------------------------多物理场混合专家模型-------------------------------------------------------\"\"\"\n",
    "# class MixtureOfExperts(nn.Module):\n",
    "#     def __init__(self, input_dim, num_experts, expert_hidden_dim):\n",
    "#         super(MixtureOfExperts, self).__init__()\n",
    "#         self.num_experts = num_experts\n",
    "#         # 专家网络\n",
    "#         self.experts = nn.ModuleList([\n",
    "#             nn.Sequential(\n",
    "#                 nn.Linear(input_dim, 2*expert_hidden_dim),\n",
    "#                 nn.ReLU(),\n",
    "#                 nn.Linear(2*expert_hidden_dim, 4*expert_hidden_dim),\n",
    "#                 nn.ReLU(),\n",
    "#                 nn.Linear(4*expert_hidden_dim, 8*expert_hidden_dim),\n",
    "#                 nn.ReLU(),\n",
    "#                 nn.Linear(8*expert_hidden_dim, 16*expert_hidden_dim),\n",
    "#                 nn.ReLU(),\n",
    "#                 nn.Linear(16*expert_hidden_dim, 8*expert_hidden_dim),\n",
    "#                 nn.ReLU(),\n",
    "#                 nn.Linear(8*expert_hidden_dim, 4*expert_hidden_dim),\n",
    "#                 nn.ReLU(),\n",
    "#                 nn.Linear(4*expert_hidden_dim,expert_hidden_dim ),\n",
    "#             )\n",
    "#             for _ in range(num_experts)\n",
    "#         ])\n",
    "#         # 门控网络\n",
    "#         self.gating_network = nn.Linear(input_dim, num_experts)\n",
    "#         # 输出层\n",
    "#         self.output_layer = nn.Linear(expert_hidden_dim, 1)\n",
    "#     def initialize_weights(self):\n",
    "#         nn.init.xavier_uniform_(self.gating_network.weight)\n",
    "#         nn.init.xavier_uniform_(self.output_layer.weight)\n",
    "#     def forward(self, x):\n",
    "#         # 计算所有专家的输出\n",
    "#         expert_outputs = torch.stack([expert(x) for expert in self.experts], dim=1)\n",
    "#         #shape(batch_size,num_expert,expert_hidden_dim)\n",
    "#         # 计算门控网络的输出并应用softmax得到权重\n",
    "#         gate_works=torch.exp(self.gating_network(x)/100)\n",
    "#         gating_outputs = F.softmax(gate_works, dim=1)\n",
    "#         # 将门控网络的输出（权重）与专家网络的输出相乘并求和\n",
    "#         combined_output = torch.sum(expert_outputs * gating_outputs.unsqueeze(-1), dim=1)\n",
    "#         # 通过输出层得到最终输出\n",
    "#         final_output = self.output_layer(combined_output)\n",
    "#         return final_output,expert_outputs      #返回总输出和每个专家输出\n",
    "#     \n",
    "# class PINN_MOE(nn.Module):\n",
    "#     def __init__(self,input_dim=11, output_dim=12, num_heads=4, head_dim=24, dropout=0,expert_input_dim=12, num_experts=3,expert_hidden_dim=24):\n",
    "#         super(PINN_MOE, self).__init__()\n",
    "#         self.Decoupling=MultiHeadAttention(input_dim, output_dim, num_heads, head_dim, dropout)\n",
    "#         self.multi_physics=MixtureOfExperts(expert_input_dim, num_experts,expert_hidden_dim)\n",
    "#         self.physics=nn.Sequential(\n",
    "#             nn.Linear(6, 32),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(32, 16),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(16, 1),\n",
    "#         )\n",
    "#         self.electricity=nn.Sequential(nn.Linear(expert_hidden_dim, 2*expert_hidden_dim),nn.ReLU(),nn.Linear(2*expert_hidden_dim,expert_hidden_dim),nn.ReLU(),nn.Linear(expert_hidden_dim,2))\n",
    "#         self.heat=nn.Sequential(nn.Linear(expert_hidden_dim, 2*expert_hidden_dim),nn.ReLU(),nn.Linear(2*expert_hidden_dim,expert_hidden_dim),nn.ReLU(),nn.Linear(expert_hidden_dim,2))\n",
    "#         self.mechine=nn.Sequential(nn.Linear(expert_hidden_dim, 2*expert_hidden_dim),nn.ReLU(),nn.Linear(2*expert_hidden_dim,expert_hidden_dim),nn.ReLU(),nn.Linear(expert_hidden_dim,2))\n",
    "#         self.parameter_heat=nn.Parameter(torch.tensor(1, dtype=torch.float32))\n",
    "#         self.parameter_electricity1=nn.Parameter(torch.tensor(1, dtype=torch.float32))\n",
    "#         self.parameter_electricity2=nn.Parameter(torch.tensor(1, dtype=torch.float32))\n",
    "#         self.soh_layer = nn.Linear(expert_hidden_dim, 1)\n",
    "#     def  initialize_weights(self):\n",
    "#         nn.init.xavier_uniform_(self.Decoupling.parameters)\n",
    "#         nn.init.xavier_uniform_(self.multi_physics.parameters)\n",
    "#         nn.init.xavier_uniform_(self.heat.parameters)\n",
    "#         nn.init.xavier_uniform_(self.mechine.parameters)\n",
    "#         nn.init.xavier_uniform_(self.electricity.parameters)\n",
    "#         nn.init.xavier_uniform_(self.physics.parameters)\n",
    "#         nn.init.xavier_uniform_(self.parameter_heat)\n",
    "#         nn.init.xavier_uniform_(self.parameter_electricity1)\n",
    "#         nn.init.xavier_uniform_(self.parameter_electricity2)\n",
    "#     def forward(self, tx):\n",
    "#         tx.requires_grad_(True)\n",
    "#         # 解耦输入\n",
    "#         t_x = self.Decoupling(tx)\n",
    "#         t=t_x[:,0:1]\n",
    "#         x=t_x[:,1:]\n",
    "#         # 预测物理量\n",
    "#         s_pred,experts = self.multi_physics(torch.cat((t,x),dim=1))\n",
    "#         # 计算 s_pred 对 t 和 x 的偏导数\n",
    "#         \"\"\"综合损失\"\"\"\n",
    "#         s_t = grad(s_pred.sum(),t,create_graph=True,only_inputs=True,allow_unused=True)[0]\n",
    "#         s_x = grad(s_pred.sum(),x,create_graph=True,only_inputs=True,allow_unused=True)[0]\n",
    "#         \"\"\"热效应损失\"\"\"\n",
    "#         T_Q=self.heat(experts[:,0:1,:].squeeze(1))\n",
    "#         T=T_Q[:,0:1]\n",
    "#         Q=T_Q[:,1:2]\n",
    "#         T_t=grad(T.sum(),t,create_graph=True,only_inputs=True,allow_unused=True)[0]\n",
    "#         T_x=grad(T.sum(),x,create_graph=True,only_inputs=True,allow_unused=True)[0]\n",
    "#         T_laplace=grad(T_t.sum(),t,create_graph=True,only_inputs=True,allow_unused=True)[0]\n",
    "#         loss_heat=torch.mean((T_t - (self.parameter_heat) * T_laplace - Q) ** 2, dim=1).unsqueeze(1)\n",
    "#         \"\"\"电化学效应损失\"\"\"\n",
    "#         phi_c=self.electricity(experts[:,1:2,:].squeeze(1))\n",
    "#         phi=phi_c[:,0:1]\n",
    "#         c=phi_c[:,1:2]\n",
    "#         phi_t=grad(phi.sum(),t,create_graph=True,only_inputs=True,allow_unused=True)[0]\n",
    "#         phi_x=grad(phi.sum(),x,create_graph=True,only_inputs=True,allow_unused=True)[0]\n",
    "#         c_x=grad(c.sum(),x,create_graph=True,only_inputs=True,allow_unused=True)[0]\n",
    "#         c_t=grad(c.sum(),t,create_graph=True,only_inputs=True,allow_unused=True)[0]\n",
    "#         phi_laplace=grad(phi_x.sum(),x,create_graph=True,only_inputs=True,allow_unused=True)[0]\n",
    "#         c_laplace=grad(c_x.sum(),x,create_graph=True,only_inputs=True,allow_unused=True)[0]\n",
    "#         loss_electricity=torch.mean((c_t -self.parameter_electricity1 * c_laplace -self.parameter_electricity2) ** 2,dim=1).unsqueeze(1)+torch.mean(phi_laplace** 2,dim=1).unsqueeze(1)\n",
    "#         \"\"\"机械应力损失\"\"\"\n",
    "#         sigma_f=self.mechine(experts[:,2:3,:].squeeze(1))\n",
    "#         sigma=sigma_f[:,0:1]\n",
    "#         f=sigma_f[:,1:2]\n",
    "#         sigma_x=grad(sigma.sum(),x,create_graph=True,only_inputs=True,allow_unused=True)[0]\n",
    "#         sigma_laplace=grad(sigma_x.sum(),x,create_graph=True,only_inputs=True,allow_unused=True)[0]\n",
    "#         loss_mechine=torch.mean((sigma_laplace + f) ** 2,dim=1).unsqueeze(1)\n",
    "#         # 打印 s_t 和 s_x，确保它们不为 None\n",
    "#         # 计算物理约束 F\n",
    "#         F_input = torch.cat([phi,c,T,Q,sigma,f], dim=1)\n",
    "#         soh = self.physics(F_input)\n",
    "#         # 计算残差 f\n",
    "#         loss_all = 1*loss_electricity+1*loss_heat+1*loss_mechine\n",
    "#         return soh, loss_all,[phi,c,T,Q,sigma,f]\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, input_dim=11, output_dim=12, num_heads=4, head_dim=24, dropout=0):\n",
    "        \"\"\"用多头注意力进行解码\"\"\"\n",
    "        \"\"\"\n",
    "        多头注意力模块。\n",
    "        :param input_dim: 输入特征维度\n",
    "        :param output_dim: 输出特征维度\n",
    "        :param num_heads: 注意力头的数量\n",
    "        :param head_dim: 每个注意力头的维度\n",
    "        :param dropout: Dropout 概率\n",
    "        \"\"\"\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.input_dim = input_dim-1\n",
    "        self.output_dim = output_dim-1\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = head_dim\n",
    "        self.dropout = dropout\n",
    "        # 线性变换层，将输入映射到 Q, K, V\n",
    "        self.query = nn.Linear(input_dim-1, num_heads * head_dim)\n",
    "        self.key = nn.Linear(input_dim-1, num_heads * head_dim)\n",
    "        self.value = nn.Linear(input_dim-1, num_heads * head_dim)\n",
    "        # 输出线性层\n",
    "        self.fc_out = nn.Linear(num_heads * head_dim, output_dim-1)\n",
    "        # Dropout 层\n",
    "        self.dropout_layer = nn.Dropout(dropout)\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        前向传播。\n",
    "        :param x: 输入张量，形状为 (batch_size, input_dim)\n",
    "        :return: 输出张量，形状为 (batch_size, output_dim)\n",
    "        \"\"\"\n",
    "        batch_size = x.size(0)\n",
    "        x_t=x[:,0].unsqueeze(1)\n",
    "        x=x[:,1:]\n",
    "        # 线性变换，得到 Q, K, V\n",
    "        Q = self.query(x).view(batch_size, -1, self.num_heads, self.head_dim).transpose(1, 2)  # (batch_size, num_heads, seq_len, head_dim)\n",
    "        K = self.key(x).view(batch_size, -1, self.num_heads, self.head_dim).transpose(1, 2)    # (batch_size, num_heads, seq_len, head_dim)\n",
    "        V = self.value(x).view(batch_size, -1, self.num_heads, self.head_dim).transpose(1, 2)  # (batch_size, num_heads, seq_len, head_dim)\n",
    "        # 计算注意力分数\n",
    "        scores = torch.matmul(Q, K.transpose(-2, -1)) / torch.sqrt(torch.tensor(self.head_dim, dtype=torch.float32))  # (batch_size, num_heads, seq_len, seq_len)\n",
    "        attention_weights = F.softmax(scores, dim=-1)  # (batch_size, num_heads, seq_len, seq_len)\n",
    "        attention_weights = self.dropout_layer(attention_weights)\n",
    "        # 计算加权和\n",
    "        attention_output = torch.matmul(attention_weights, V)  # (batch_size, num_heads, seq_len, head_dim)\n",
    "        # 拼接多头输出\n",
    "        attention_output = attention_output.transpose(1, 2).contiguous().view(batch_size, -1, self.num_heads * self.head_dim)  # (batch_size, seq_len, num_heads * head_dim)\n",
    "        # 通过线性层映射到输出维度\n",
    "        output = self.fc_out(attention_output)  # (batch_size, seq_len, output_dim)\n",
    "        output=torch.cat((x_t,output.squeeze(1)),dim=-1)\n",
    "        return output  # (batch_size, output_dim)\n",
    "\"\"\"--------------------------------------------------------多物理场混合专家模型-------------------------------------------------------\"\"\"\n",
    "class MixtureOfExperts(nn.Module):\n",
    "    def __init__(self, input_dim, num_experts, expert_hidden_dim):\n",
    "        super(MixtureOfExperts, self).__init__()\n",
    "        self.num_experts = num_experts\n",
    "        # 专家网络\n",
    "        self.experts = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(input_dim, 2*expert_hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(2*expert_hidden_dim, 4*expert_hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(4*expert_hidden_dim, 8*expert_hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(8*expert_hidden_dim, 16*expert_hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(16*expert_hidden_dim, 32*expert_hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(32*expert_hidden_dim,64*expert_hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(64*expert_hidden_dim,32*expert_hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(32*expert_hidden_dim,16*expert_hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(16*expert_hidden_dim, 8*expert_hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(8*expert_hidden_dim, 4*expert_hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(4*expert_hidden_dim,expert_hidden_dim ),\n",
    "            )\n",
    "            for _ in range(num_experts)\n",
    "        ])\n",
    "        # 门控网络\n",
    "        self.gating_network = nn.Linear(input_dim, num_experts)\n",
    "        # 输出层\n",
    "        self.output_layer = nn.Linear(expert_hidden_dim, 1)\n",
    "    def initialize_weights(self):\n",
    "        nn.init.xavier_uniform_(self.gating_network.weight)\n",
    "        nn.init.xavier_uniform_(self.output_layer.weight)\n",
    "    def forward(self, x):\n",
    "        # 计算所有专家的输出\n",
    "        expert_outputs = torch.stack([expert(x) for expert in self.experts], dim=1)\n",
    "        #shape(batch_size,num_expert,expert_hidden_dim)\n",
    "        # 计算门控网络的输出并应用softmax得到权重\n",
    "        gate_works=torch.exp(self.gating_network(x)/10)\n",
    "        gating_outputs = F.softmax(gate_works, dim=1)\n",
    "        # 将门控网络的输出（权重）与专家网络的输出相乘并求和\n",
    "        combined_output = torch.sum(expert_outputs * gating_outputs.unsqueeze(-1), dim=1)\n",
    "        # 通过输出层得到最终输出\n",
    "        final_output = self.output_layer(combined_output)\n",
    "        return final_output,expert_outputs      #返回总输出和每个专家输出\n",
    "    \n",
    "class PINN_MOE(nn.Module):\n",
    "    def __init__(self,input_dim=11, output_dim=12, num_heads=4, head_dim=24, dropout=0,expert_input_dim=12, num_experts=3,expert_hidden_dim=2):\n",
    "        super(PINN_MOE, self).__init__()\n",
    "        self.Decoupling=MultiHeadAttention(input_dim, output_dim, num_heads, head_dim, dropout)\n",
    "        self.multi_physics=MixtureOfExperts(expert_input_dim, num_experts,expert_hidden_dim)\n",
    "        self.physics=nn.Sequential(\n",
    "            nn.Linear(6, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 1),\n",
    "        )\n",
    "        # self.electricity=nn.Sequential(nn.Linear(expert_hidden_dim, 2*expert_hidden_dim),nn.ReLU(),nn.Linear(2*expert_hidden_dim,expert_hidden_dim),nn.ReLU(),nn.Linear(expert_hidden_dim,2))\n",
    "        # self.heat=nn.Sequential(nn.Linear(expert_hidden_dim, 2*expert_hidden_dim),nn.ReLU(),nn.Linear(2*expert_hidden_dim,expert_hidden_dim),nn.ReLU(),nn.Linear(expert_hidden_dim,2))\n",
    "        # self.mechine=nn.Sequential(nn.Linear(expert_hidden_dim, 2*expert_hidden_dim),nn.ReLU(),nn.Linear(2*expert_hidden_dim,expert_hidden_dim),nn.ReLU(),nn.Linear(expert_hidden_dim,2))\n",
    "        self.parameter_heat=nn.Parameter(torch.tensor(1, dtype=torch.float32))\n",
    "        self.parameter_electricity1=nn.Parameter(torch.tensor(1, dtype=torch.float32))\n",
    "        self.parameter_electricity2=nn.Parameter(torch.tensor(1, dtype=torch.float32))\n",
    "    def  initialize_weights(self):\n",
    "        nn.init.xavier_uniform_(self.Decoupling.parameters)\n",
    "        nn.init.xavier_uniform_(self.multi_physics.parameters)\n",
    "        # nn.init.xavier_uniform_(self.heat.parameters)\n",
    "        # nn.init.xavier_uniform_(self.mechine.parameters)\n",
    "        # nn.init.xavier_uniform_(self.electricity.parameters)\n",
    "        nn.init.xavier_uniform_(self.physics.parameters)\n",
    "        nn.init.xavier_uniform_(self.parameter_heat)\n",
    "        nn.init.xavier_uniform_(self.parameter_electricity1)\n",
    "        nn.init.xavier_uniform_(self.parameter_electricity2)\n",
    "    def forward(self, tx):\n",
    "        tx.requires_grad_(True)\n",
    "        # 解耦输入\n",
    "        t_x = self.Decoupling(tx)\n",
    "        t=t_x[:,0:1]\n",
    "        x=t_x[:,1:]\n",
    "        # 预测物理量\n",
    "        s_pred,experts = self.multi_physics(torch.cat((t,x),dim=1))\n",
    "        # 计算 s_pred 对 t 和 x 的偏导数\n",
    "        \"\"\"综合损失\"\"\"\n",
    "        s_t = grad(s_pred.sum(),t,create_graph=True,only_inputs=True,allow_unused=True)[0]\n",
    "        s_x = grad(s_pred.sum(),x,create_graph=True,only_inputs=True,allow_unused=True)[0]\n",
    "        \"\"\"热效应损失\"\"\"\n",
    "        T_Q=experts[:,0:1,:].squeeze(1)\n",
    "        # print(T_Q.shape)\n",
    "        T=T_Q[:,0:1]\n",
    "        Q=T_Q[:,1:2]\n",
    "        T_t=grad(T.sum(),t,create_graph=True,only_inputs=True,allow_unused=True)[0]\n",
    "        T_x=grad(T.sum(),x,create_graph=True,only_inputs=True,allow_unused=True)[0]\n",
    "        T_laplace=grad(T_t.sum(),t,create_graph=True,only_inputs=True,allow_unused=True)[0]\n",
    "        loss_heat=torch.mean((T_t - (self.parameter_heat) * T_laplace - Q) ** 2, dim=1).unsqueeze(1)\n",
    "        \"\"\"电化学效应损失\"\"\"\n",
    "        phi_c=experts[:,1:2,:].squeeze(1)\n",
    "        phi=phi_c[:,0:1]\n",
    "        c=phi_c[:,1:2]\n",
    "        phi_t=grad(phi.sum(),t,create_graph=True,only_inputs=True,allow_unused=True)[0]\n",
    "        phi_x=grad(phi.sum(),x,create_graph=True,only_inputs=True,allow_unused=True)[0]\n",
    "        c_x=grad(c.sum(),x,create_graph=True,only_inputs=True,allow_unused=True)[0]\n",
    "        c_t=grad(c.sum(),t,create_graph=True,only_inputs=True,allow_unused=True)[0]\n",
    "        phi_laplace=grad(phi_x.sum(),x,create_graph=True,only_inputs=True,allow_unused=True)[0]\n",
    "        c_laplace=grad(c_x.sum(),x,create_graph=True,only_inputs=True,allow_unused=True)[0]\n",
    "        loss_electricity=torch.mean((c_t -self.parameter_electricity1 * c_laplace -self.parameter_electricity2) ** 2,dim=1).unsqueeze(1)+torch.mean(phi_laplace** 2,dim=1).unsqueeze(1)\n",
    "        \"\"\"机械应力损失\"\"\"\n",
    "        sigma_f=experts[:,2:3,:].squeeze(1)\n",
    "        sigma=sigma_f[:,0:1]\n",
    "        f=sigma_f[:,1:2]\n",
    "        sigma_x=grad(sigma.sum(),x,create_graph=True,only_inputs=True,allow_unused=True)[0]\n",
    "        sigma_laplace=grad(sigma_x.sum(),x,create_graph=True,only_inputs=True,allow_unused=True)[0]\n",
    "        loss_mechine=torch.mean((sigma_laplace + f) ** 2,dim=1).unsqueeze(1)\n",
    "        # 打印 s_t 和 s_x，确保它们不为 None\n",
    "        # 计算物理约束 F\n",
    "        F_input = torch.cat([phi,c,T,Q,sigma,f], dim=1)\n",
    "        soh = self.physics(F_input)\n",
    "        # 计算残差 f\n",
    "        loss_all = 1*loss_electricity+1*loss_heat+1*loss_mechine\n",
    "        return soh, loss_all,[phi,c,T,Q,sigma,f]"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "id": "cefa752045ad9574",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T06:34:11.501411Z",
     "start_time": "2025-03-31T06:34:11.488989Z"
    }
   },
   "source": [
    "def train(lr=0.003,epochs=150, weight_decay=0, seed=0, metric='rmse', device='cpu'):\n",
    "    \"\"\"function for train\"\"\"\n",
    "    setup_seed(seed)\n",
    "    print(\"training seed \"+str(seed)+':\\n')\n",
    "    train_loader, val_loader, test_35_data, test_36_data, test_37_data,test_38_data=get_data()\n",
    "    test_data=[test_35_data, test_36_data, test_37_data,test_38_data]\n",
    "    model = PINN_MOE()\n",
    "    model=model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    criterion = nn.MSELoss()\n",
    "    len_dataloader = len(train_loader)\n",
    "    test_results=[]\n",
    "    lists=[]\n",
    "    \"\"\"早停止获取最佳模型\"\"\"\n",
    "    val_mse=10\n",
    "    for epoch in range(epochs):\n",
    "        loss_epoch=0\n",
    "        for X,y in train_loader:\n",
    "            X,y = X.to(device), y.to(device)\n",
    "            y_pred,f,_= model(X)\n",
    "            f_target = torch.zeros_like(f)\n",
    "            y_pred = y_pred.squeeze(1)\n",
    "            loss = criterion(y_pred,y)+0.3*criterion(f,f_target)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_epoch += loss\n",
    "        if (epoch+1)%5==0 and epoch!=0:\n",
    "            print('Epoch:',epoch+1,'Train_RMSELoss:',loss_epoch/len_dataloader,'\\n')\n",
    "        if (epoch+1)%5==0 and epoch!=0:\n",
    "            val_loss=0\n",
    "            for val_x,val_y in val_loader:\n",
    "                val_x,val_y=val_x.to(device),val_y.to(device)\n",
    "                pre,_,_=model(val_x)\n",
    "                val_loss+=criterion(pre.squeeze(1),val_y).detach()    \n",
    "            print('Epoch:',epoch+1,'valid_RMSELoss:',val_loss/len(val_loader),'\\n')\n",
    "            val_mse=val_loss/len(val_loader)\n",
    "                \n",
    "        if val_mse<0.0004 or (epoch+1)==epochs:\n",
    "            model=model.cpu()\n",
    "            for name in test_data:\n",
    "                X=torch.from_numpy(name[0]).float()\n",
    "                y=name[1]\n",
    "                y_pred,_,list=model(X)\n",
    "                for i in range(len(list)):\n",
    "                    list[i]=list[i].detach().cpu().numpy()\n",
    "                lists.append(list)\n",
    "                y_pred= y_pred.squeeze(0).detach().numpy()\n",
    "                test_results.append([y,y_pred])\n",
    "            break\n",
    "    return test_results,lists"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "id": "f0d89aa69f7a0378",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T06:37:25.869512Z",
     "start_time": "2025-03-31T06:34:12.173665Z"
    }
   },
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "test_results,lists=train(seed=0,device=device)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training seed 0:\n",
      "\n",
      "Epoch: 5 Train_RMSELoss: tensor(0.6868, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 5 valid_RMSELoss: tensor(0.4090, device='cuda:0') \n",
      "\n",
      "Epoch: 10 Train_RMSELoss: tensor(0.5290, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 10 valid_RMSELoss: tensor(0.2394, device='cuda:0') \n",
      "\n",
      "Epoch: 15 Train_RMSELoss: tensor(0.4074, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 15 valid_RMSELoss: tensor(0.1131, device='cuda:0') \n",
      "\n",
      "Epoch: 20 Train_RMSELoss: tensor(0.3468, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 20 valid_RMSELoss: tensor(0.1442, device='cuda:0') \n",
      "\n",
      "Epoch: 25 Train_RMSELoss: tensor(0.3023, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 25 valid_RMSELoss: tensor(0.0948, device='cuda:0') \n",
      "\n",
      "Epoch: 30 Train_RMSELoss: tensor(0.2783, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 30 valid_RMSELoss: tensor(0.0691, device='cuda:0') \n",
      "\n",
      "Epoch: 35 Train_RMSELoss: tensor(0.2436, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 35 valid_RMSELoss: tensor(0.0629, device='cuda:0') \n",
      "\n",
      "Epoch: 40 Train_RMSELoss: tensor(0.2251, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 40 valid_RMSELoss: tensor(0.0511, device='cuda:0') \n",
      "\n",
      "Epoch: 45 Train_RMSELoss: tensor(0.2035, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 45 valid_RMSELoss: tensor(0.0339, device='cuda:0') \n",
      "\n",
      "Epoch: 50 Train_RMSELoss: tensor(0.1885, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 50 valid_RMSELoss: tensor(0.0261, device='cuda:0') \n",
      "\n",
      "Epoch: 55 Train_RMSELoss: tensor(0.1729, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 55 valid_RMSELoss: tensor(0.0223, device='cuda:0') \n",
      "\n",
      "Epoch: 60 Train_RMSELoss: tensor(0.1605, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 60 valid_RMSELoss: tensor(0.0180, device='cuda:0') \n",
      "\n",
      "Epoch: 65 Train_RMSELoss: tensor(0.1492, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 65 valid_RMSELoss: tensor(0.0132, device='cuda:0') \n",
      "\n",
      "Epoch: 70 Train_RMSELoss: tensor(0.1393, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 70 valid_RMSELoss: tensor(0.0101, device='cuda:0') \n",
      "\n",
      "Epoch: 75 Train_RMSELoss: tensor(0.1303, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 75 valid_RMSELoss: tensor(0.0086, device='cuda:0') \n",
      "\n",
      "Epoch: 80 Train_RMSELoss: tensor(0.1222, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 80 valid_RMSELoss: tensor(0.0071, device='cuda:0') \n",
      "\n",
      "Epoch: 85 Train_RMSELoss: tensor(0.1147, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 85 valid_RMSELoss: tensor(0.0053, device='cuda:0') \n",
      "\n",
      "Epoch: 90 Train_RMSELoss: tensor(0.1076, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 90 valid_RMSELoss: tensor(0.0043, device='cuda:0') \n",
      "\n",
      "Epoch: 95 Train_RMSELoss: tensor(0.1011, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 95 valid_RMSELoss: tensor(0.0029, device='cuda:0') \n",
      "\n",
      "Epoch: 100 Train_RMSELoss: tensor(0.0952, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 100 valid_RMSELoss: tensor(0.0021, device='cuda:0') \n",
      "\n",
      "Epoch: 105 Train_RMSELoss: tensor(0.0900, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 105 valid_RMSELoss: tensor(0.0014, device='cuda:0') \n",
      "\n",
      "Epoch: 110 Train_RMSELoss: tensor(0.0855, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 110 valid_RMSELoss: tensor(0.0012, device='cuda:0') \n",
      "\n",
      "Epoch: 115 Train_RMSELoss: tensor(0.0813, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 115 valid_RMSELoss: tensor(0.0012, device='cuda:0') \n",
      "\n",
      "Epoch: 120 Train_RMSELoss: tensor(0.0770, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 120 valid_RMSELoss: tensor(0.0013, device='cuda:0') \n",
      "\n",
      "Epoch: 125 Train_RMSELoss: tensor(0.0731, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 125 valid_RMSELoss: tensor(0.0012, device='cuda:0') \n",
      "\n",
      "Epoch: 130 Train_RMSELoss: tensor(0.0695, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 130 valid_RMSELoss: tensor(0.0013, device='cuda:0') \n",
      "\n",
      "Epoch: 135 Train_RMSELoss: tensor(0.0661, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 135 valid_RMSELoss: tensor(0.0013, device='cuda:0') \n",
      "\n",
      "Epoch: 140 Train_RMSELoss: tensor(0.0629, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 140 valid_RMSELoss: tensor(0.0013, device='cuda:0') \n",
      "\n",
      "Epoch: 145 Train_RMSELoss: tensor(0.0600, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 145 valid_RMSELoss: tensor(0.0013, device='cuda:0') \n",
      "\n",
      "Epoch: 150 Train_RMSELoss: tensor(0.0571, device='cuda:0', grad_fn=<DivBackward0>) \n",
      "\n",
      "Epoch: 150 valid_RMSELoss: tensor(0.0013, device='cuda:0') \n",
      "\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "id": "e5998d686c61c2ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T06:37:30.043584Z",
     "start_time": "2025-03-31T06:37:29.869044Z"
    }
   },
   "source": [
    "plt.rcParams['xtick.labelsize'] = 16\n",
    "fig, axes = plt.subplots(4, 1, figsize=(8, 16))\n",
    "for i in range(4):\n",
    "    # axes[i].plot(test_results[i][0][:800])\n",
    "    # axes[i].plot(test_results[i][1][:800])\n",
    "    axes[i].plot(lists[i][4])\n",
    "    #axes[i].set_xticks([])\n",
    "    axes[i].set_yticks([])\n",
    "    axes[i].tick_params(axis='both', which='both', length=0)\n",
    "    axes[i].set_xlabel('cycle',fontsize=20)\n",
    "    axes[i].set_ylabel('Temperature  param',fontsize=20)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 800x1600 with 4 Axes>"
      ],
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"504.183612pt\" height=\"943.78125pt\" viewBox=\"0 0 504.183612 943.78125\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n <metadata>\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2025-03-31T14:37:30.010523</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.7.2, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 943.78125 \nL 504.183612 943.78125 \nL 504.183612 0 \nL 0 0 \nz\n\" style=\"fill: #ffffff\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 30.55625 200.034783 \nL 476.95625 200.034783 \nL 476.95625 7.2 \nL 30.55625 7.2 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\"/>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(45.757159 215.692283) scale(0.16 -0.16)\">\n       <defs>\n        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\"/>\n     <g id=\"text_2\">\n      <!-- 250 -->\n      <g transform=\"translate(90.387827 215.692283) scale(0.16 -0.16)\">\n       <defs>\n        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \nL 3169 4666 \nL 3169 4134 \nL 1269 4134 \nL 1269 2991 \nQ 1406 3038 1543 3061 \nQ 1681 3084 1819 3084 \nQ 2600 3084 3056 2656 \nQ 3513 2228 3513 1497 \nQ 3513 744 3044 326 \nQ 2575 -91 1722 -91 \nQ 1428 -91 1123 -41 \nQ 819 9 494 109 \nL 494 744 \nQ 775 591 1075 516 \nQ 1375 441 1709 441 \nQ 2250 441 2565 725 \nQ 2881 1009 2881 1497 \nQ 2881 1984 2565 2268 \nQ 2250 2553 1709 2553 \nQ 1456 2553 1204 2497 \nQ 953 2441 691 2322 \nL 691 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\"/>\n     <g id=\"text_3\">\n      <!-- 500 -->\n      <g transform=\"translate(145.198494 215.692283) scale(0.16 -0.16)\">\n       <use xlink:href=\"#DejaVuSans-35\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\"/>\n     <g id=\"text_4\">\n      <!-- 750 -->\n      <g transform=\"translate(200.009161 215.692283) scale(0.16 -0.16)\">\n       <defs>\n        <path id=\"DejaVuSans-37\" d=\"M 525 4666 \nL 3525 4666 \nL 3525 4397 \nL 1831 0 \nL 1172 0 \nL 2766 4134 \nL 525 4134 \nL 525 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-37\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\"/>\n     <g id=\"text_5\">\n      <!-- 1000 -->\n      <g transform=\"translate(249.729829 215.692283) scale(0.16 -0.16)\">\n       <defs>\n        <path id=\"DejaVuSans-31\" d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\"/>\n     <g id=\"text_6\">\n      <!-- 1250 -->\n      <g transform=\"translate(304.540496 215.692283) scale(0.16 -0.16)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_7\"/>\n     <g id=\"text_7\">\n      <!-- 1500 -->\n      <g transform=\"translate(359.351164 215.692283) scale(0.16 -0.16)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_8\">\n     <g id=\"line2d_8\"/>\n     <g id=\"text_8\">\n      <!-- 1750 -->\n      <g transform=\"translate(414.161831 215.692283) scale(0.16 -0.16)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-37\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_9\">\n     <!-- cycle -->\n     <g transform=\"translate(227.909375 238.216658) scale(0.2 -0.2)\">\n      <defs>\n       <path id=\"DejaVuSans-63\" d=\"M 3122 3366 \nL 3122 2828 \nQ 2878 2963 2633 3030 \nQ 2388 3097 2138 3097 \nQ 1578 3097 1268 2742 \nQ 959 2388 959 1747 \nQ 959 1106 1268 751 \nQ 1578 397 2138 397 \nQ 2388 397 2633 464 \nQ 2878 531 3122 666 \nL 3122 134 \nQ 2881 22 2623 -34 \nQ 2366 -91 2075 -91 \nQ 1284 -91 818 406 \nQ 353 903 353 1747 \nQ 353 2603 823 3093 \nQ 1294 3584 2113 3584 \nQ 2378 3584 2631 3529 \nQ 2884 3475 3122 3366 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-79\" d=\"M 2059 -325 \nQ 1816 -950 1584 -1140 \nQ 1353 -1331 966 -1331 \nL 506 -1331 \nL 506 -850 \nL 844 -850 \nQ 1081 -850 1212 -737 \nQ 1344 -625 1503 -206 \nL 1606 56 \nL 191 3500 \nL 800 3500 \nL 1894 763 \nL 2988 3500 \nL 3597 3500 \nL 2059 -325 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \nL 1178 4863 \nL 1178 0 \nL 603 0 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \nL 3597 1613 \nL 953 1613 \nQ 991 1019 1311 708 \nQ 1631 397 2203 397 \nQ 2534 397 2845 478 \nQ 3156 559 3463 722 \nL 3463 178 \nQ 3153 47 2828 -22 \nQ 2503 -91 2169 -91 \nQ 1331 -91 842 396 \nQ 353 884 353 1716 \nQ 353 2575 817 3079 \nQ 1281 3584 2069 3584 \nQ 2775 3584 3186 3129 \nQ 3597 2675 3597 1894 \nz\nM 3022 2063 \nQ 3016 2534 2758 2815 \nQ 2500 3097 2075 3097 \nQ 1594 3097 1305 2825 \nQ 1016 2553 972 2059 \nL 3022 2063 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-63\"/>\n      <use xlink:href=\"#DejaVuSans-79\" x=\"54.980469\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"114.160156\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"169.140625\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"196.923828\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"text_10\">\n     <!-- Temperature  param -->\n     <g transform=\"translate(22.396875 205.768954) rotate(-90) scale(0.2 -0.2)\">\n      <defs>\n       <path id=\"DejaVuSans-54\" d=\"M -19 4666 \nL 3928 4666 \nL 3928 4134 \nL 2272 4134 \nL 2272 0 \nL 1638 0 \nL 1638 4134 \nL -19 4134 \nL -19 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6d\" d=\"M 3328 2828 \nQ 3544 3216 3844 3400 \nQ 4144 3584 4550 3584 \nQ 5097 3584 5394 3201 \nQ 5691 2819 5691 2113 \nL 5691 0 \nL 5113 0 \nL 5113 2094 \nQ 5113 2597 4934 2840 \nQ 4756 3084 4391 3084 \nQ 3944 3084 3684 2787 \nQ 3425 2491 3425 1978 \nL 3425 0 \nL 2847 0 \nL 2847 2094 \nQ 2847 2600 2669 2842 \nQ 2491 3084 2119 3084 \nQ 1678 3084 1418 2786 \nQ 1159 2488 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1356 3278 1631 3431 \nQ 1906 3584 2284 3584 \nQ 2666 3584 2933 3390 \nQ 3200 3197 3328 2828 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-70\" d=\"M 1159 525 \nL 1159 -1331 \nL 581 -1331 \nL 581 3500 \nL 1159 3500 \nL 1159 2969 \nQ 1341 3281 1617 3432 \nQ 1894 3584 2278 3584 \nQ 2916 3584 3314 3078 \nQ 3713 2572 3713 1747 \nQ 3713 922 3314 415 \nQ 2916 -91 2278 -91 \nQ 1894 -91 1617 61 \nQ 1341 213 1159 525 \nz\nM 3116 1747 \nQ 3116 2381 2855 2742 \nQ 2594 3103 2138 3103 \nQ 1681 3103 1420 2742 \nQ 1159 2381 1159 1747 \nQ 1159 1113 1420 752 \nQ 1681 391 2138 391 \nQ 2594 391 2855 752 \nQ 3116 1113 3116 1747 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \nQ 2534 3019 2420 3045 \nQ 2306 3072 2169 3072 \nQ 1681 3072 1420 2755 \nQ 1159 2438 1159 1844 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1341 3275 1631 3429 \nQ 1922 3584 2338 3584 \nQ 2397 3584 2469 3576 \nQ 2541 3569 2628 3553 \nL 2631 2963 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \nQ 1497 1759 1228 1600 \nQ 959 1441 959 1056 \nQ 959 750 1161 570 \nQ 1363 391 1709 391 \nQ 2188 391 2477 730 \nQ 2766 1069 2766 1631 \nL 2766 1759 \nL 2194 1759 \nz\nM 3341 1997 \nL 3341 0 \nL 2766 0 \nL 2766 531 \nQ 2569 213 2275 61 \nQ 1981 -91 1556 -91 \nQ 1019 -91 701 211 \nQ 384 513 384 1019 \nQ 384 1609 779 1909 \nQ 1175 2209 1959 2209 \nL 2766 2209 \nL 2766 2266 \nQ 2766 2663 2505 2880 \nQ 2244 3097 1772 3097 \nQ 1472 3097 1187 3025 \nQ 903 2953 641 2809 \nL 641 3341 \nQ 956 3463 1253 3523 \nQ 1550 3584 1831 3584 \nQ 2591 3584 2966 3190 \nQ 3341 2797 3341 1997 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-74\" d=\"M 1172 4494 \nL 1172 3500 \nL 2356 3500 \nL 2356 3053 \nL 1172 3053 \nL 1172 1153 \nQ 1172 725 1289 603 \nQ 1406 481 1766 481 \nL 2356 481 \nL 2356 0 \nL 1766 0 \nQ 1100 0 847 248 \nQ 594 497 594 1153 \nL 594 3053 \nL 172 3053 \nL 172 3500 \nL 594 3500 \nL 594 4494 \nL 1172 4494 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-75\" d=\"M 544 1381 \nL 544 3500 \nL 1119 3500 \nL 1119 1403 \nQ 1119 906 1312 657 \nQ 1506 409 1894 409 \nQ 2359 409 2629 706 \nQ 2900 1003 2900 1516 \nL 2900 3500 \nL 3475 3500 \nL 3475 0 \nL 2900 0 \nL 2900 538 \nQ 2691 219 2414 64 \nQ 2138 -91 1772 -91 \nQ 1169 -91 856 284 \nQ 544 659 544 1381 \nz\nM 1991 3584 \nL 1991 3584 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-20\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-54\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"44.083984\"/>\n      <use xlink:href=\"#DejaVuSans-6d\" x=\"105.607422\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"203.019531\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"266.496094\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"328.019531\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"369.132812\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"430.412109\"/>\n      <use xlink:href=\"#DejaVuSans-75\" x=\"469.621094\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"533\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"571.863281\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"633.386719\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"665.173828\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"696.960938\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"760.4375\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"821.716797\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"862.830078\"/>\n      <use xlink:href=\"#DejaVuSans-6d\" x=\"924.109375\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_9\">\n    <path d=\"M 50.847159 190.825303 \nL 51.504887 190.809656 \nL 52.162615 190.842475 \nL 54.135799 191.080665 \nL 54.574284 191.269565 \nL 55.232012 191.19306 \nL 56.766711 191.095786 \nL 58.739895 190.790075 \nL 59.836109 190.558942 \nL 62.905506 189.784013 \nL 106.096312 174.270134 \nL 128.678307 164.080407 \nL 133.06316 162.088738 \nL 137.448014 160.137493 \nL 153.671971 152.80918 \nL 156.083641 151.728443 \nL 158.276067 150.733603 \nL 229.09145 118.734055 \nL 249.042533 109.718236 \nL 279.298021 96.079205 \nL 284.340602 93.795136 \nL 289.163941 91.614109 \nL 291.794853 90.434197 \nL 292.891067 89.940431 \nL 437.152743 24.790645 \nL 440.660626 23.20196 \nL 456.665341 15.965217 \nL 456.665341 15.965217 \n\" clip-path=\"url(#p909d86f1f6)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 30.55625 200.034783 \nL 30.55625 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 476.95625 200.034783 \nL 476.95625 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 30.55625 200.034783 \nL 476.95625 200.034783 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 30.55625 7.2 \nL 476.95625 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n  </g>\n  <g id=\"axes_2\">\n   <g id=\"patch_7\">\n    <path d=\"M 30.55625 431.436522 \nL 476.95625 431.436522 \nL 476.95625 238.601739 \nL 30.55625 238.601739 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g id=\"matplotlib.axis_3\">\n    <g id=\"xtick_9\">\n     <g id=\"line2d_10\"/>\n     <g id=\"text_11\">\n      <!-- 0 -->\n      <g transform=\"translate(45.757159 447.094022) scale(0.16 -0.16)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_10\">\n     <g id=\"line2d_11\"/>\n     <g id=\"text_12\">\n      <!-- 200 -->\n      <g transform=\"translate(95.081291 447.094022) scale(0.16 -0.16)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_11\">\n     <g id=\"line2d_12\"/>\n     <g id=\"text_13\">\n      <!-- 400 -->\n      <g transform=\"translate(154.585424 447.094022) scale(0.16 -0.16)\">\n       <defs>\n        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \nL 825 1625 \nL 2419 1625 \nL 2419 4116 \nz\nM 2253 4666 \nL 3047 4666 \nL 3047 1625 \nL 3713 1625 \nL 3713 1100 \nL 3047 1100 \nL 3047 0 \nL 2419 0 \nL 2419 1100 \nL 313 1100 \nL 313 1709 \nL 2253 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-34\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_12\">\n     <g id=\"line2d_13\"/>\n     <g id=\"text_14\">\n      <!-- 600 -->\n      <g transform=\"translate(214.089556 447.094022) scale(0.16 -0.16)\">\n       <defs>\n        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \nQ 1688 2584 1439 2293 \nQ 1191 2003 1191 1497 \nQ 1191 994 1439 701 \nQ 1688 409 2113 409 \nQ 2538 409 2786 701 \nQ 3034 994 3034 1497 \nQ 3034 2003 2786 2293 \nQ 2538 2584 2113 2584 \nz\nM 3366 4563 \nL 3366 3988 \nQ 3128 4100 2886 4159 \nQ 2644 4219 2406 4219 \nQ 1781 4219 1451 3797 \nQ 1122 3375 1075 2522 \nQ 1259 2794 1537 2939 \nQ 1816 3084 2150 3084 \nQ 2853 3084 3261 2657 \nQ 3669 2231 3669 1497 \nQ 3669 778 3244 343 \nQ 2819 -91 2113 -91 \nQ 1303 -91 875 529 \nQ 447 1150 447 2328 \nQ 447 3434 972 4092 \nQ 1497 4750 2381 4750 \nQ 2619 4750 2861 4703 \nQ 3103 4656 3366 4563 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-36\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_13\">\n     <g id=\"line2d_14\"/>\n     <g id=\"text_15\">\n      <!-- 800 -->\n      <g transform=\"translate(273.593688 447.094022) scale(0.16 -0.16)\">\n       <defs>\n        <path id=\"DejaVuSans-38\" d=\"M 2034 2216 \nQ 1584 2216 1326 1975 \nQ 1069 1734 1069 1313 \nQ 1069 891 1326 650 \nQ 1584 409 2034 409 \nQ 2484 409 2743 651 \nQ 3003 894 3003 1313 \nQ 3003 1734 2745 1975 \nQ 2488 2216 2034 2216 \nz\nM 1403 2484 \nQ 997 2584 770 2862 \nQ 544 3141 544 3541 \nQ 544 4100 942 4425 \nQ 1341 4750 2034 4750 \nQ 2731 4750 3128 4425 \nQ 3525 4100 3525 3541 \nQ 3525 3141 3298 2862 \nQ 3072 2584 2669 2484 \nQ 3125 2378 3379 2068 \nQ 3634 1759 3634 1313 \nQ 3634 634 3220 271 \nQ 2806 -91 2034 -91 \nQ 1263 -91 848 271 \nQ 434 634 434 1313 \nQ 434 1759 690 2068 \nQ 947 2378 1403 2484 \nz\nM 1172 3481 \nQ 1172 3119 1398 2916 \nQ 1625 2713 2034 2713 \nQ 2441 2713 2670 2916 \nQ 2900 3119 2900 3481 \nQ 2900 3844 2670 4047 \nQ 2441 4250 2034 4250 \nQ 1625 4250 1398 4047 \nQ 1172 3844 1172 3481 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-38\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_14\">\n     <g id=\"line2d_15\"/>\n     <g id=\"text_16\">\n      <!-- 1000 -->\n      <g transform=\"translate(328.00782 447.094022) scale(0.16 -0.16)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_15\">\n     <g id=\"line2d_16\"/>\n     <g id=\"text_17\">\n      <!-- 1200 -->\n      <g transform=\"translate(387.511952 447.094022) scale(0.16 -0.16)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_16\">\n     <g id=\"line2d_17\"/>\n     <g id=\"text_18\">\n      <!-- 1400 -->\n      <g transform=\"translate(447.016085 447.094022) scale(0.16 -0.16)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-34\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_19\">\n     <!-- cycle -->\n     <g transform=\"translate(227.909375 469.618397) scale(0.2 -0.2)\">\n      <use xlink:href=\"#DejaVuSans-63\"/>\n      <use xlink:href=\"#DejaVuSans-79\" x=\"54.980469\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"114.160156\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"169.140625\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"196.923828\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_4\">\n    <g id=\"text_20\">\n     <!-- Temperature  param -->\n     <g transform=\"translate(22.396875 437.170693) rotate(-90) scale(0.2 -0.2)\">\n      <use xlink:href=\"#DejaVuSans-54\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"44.083984\"/>\n      <use xlink:href=\"#DejaVuSans-6d\" x=\"105.607422\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"203.019531\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"266.496094\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"328.019531\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"369.132812\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"430.412109\"/>\n      <use xlink:href=\"#DejaVuSans-75\" x=\"469.621094\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"533\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"571.863281\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"633.386719\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"665.173828\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"696.960938\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"760.4375\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"821.716797\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"862.830078\"/>\n      <use xlink:href=\"#DejaVuSans-6d\" x=\"924.109375\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_18\">\n    <path d=\"M 50.847159 422.0513 \nL 51.4422 422.098557 \nL 52.037242 422.01235 \nL 52.632283 422.14048 \nL 54.417407 422.330123 \nL 55.012448 422.312675 \nL 55.90501 422.475631 \nL 56.500052 422.547971 \nL 57.690134 422.619762 \nL 59.475258 422.333296 \nL 60.36782 422.284901 \nL 65.425671 421.346798 \nL 66.615754 420.943437 \nL 82.086829 415.341245 \nL 118.384349 402.223798 \nL 121.062035 401.242254 \nL 123.739721 400.279959 \nL 126.119886 399.219484 \nL 128.202531 398.250126 \nL 131.177738 396.876538 \nL 133.557903 395.799812 \nL 140.400878 392.630706 \nL 147.541374 389.334897 \nL 160.929804 383.206671 \nL 161.822366 382.790869 \nL 163.60749 381.977915 \nL 165.987655 380.881375 \nL 169.260382 379.403124 \nL 207.938068 361.623351 \nL 211.805837 359.851887 \nL 212.995919 359.281813 \nL 243.938068 345.054602 \nL 245.425671 344.360259 \nL 253.161209 340.76568 \nL 254.351291 340.23913 \nL 258.21906 338.45357 \nL 353.723192 294.628841 \nL 383.772779 280.830654 \nL 389.723192 278.101902 \nL 390.615754 277.707137 \nL 395.376085 275.520314 \nL 402.516581 272.249669 \nL 411.14468 268.27146 \nL 421.260382 263.637986 \nL 428.400878 260.351279 \nL 431.971126 258.724233 \nL 435.541374 257.070505 \nL 448.632283 251.045744 \nL 455.177738 248.022462 \nL 456.665341 247.366957 \nL 456.665341 247.366957 \n\" clip-path=\"url(#p0bb4cf4a46)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_8\">\n    <path d=\"M 30.55625 431.436522 \nL 30.55625 238.601739 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_9\">\n    <path d=\"M 476.95625 431.436522 \nL 476.95625 238.601739 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_10\">\n    <path d=\"M 30.55625 431.436522 \nL 476.95625 431.436522 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_11\">\n    <path d=\"M 30.55625 238.601739 \nL 476.95625 238.601739 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n  </g>\n  <g id=\"axes_3\">\n   <g id=\"patch_12\">\n    <path d=\"M 30.55625 662.838261 \nL 476.95625 662.838261 \nL 476.95625 470.003478 \nL 30.55625 470.003478 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g id=\"matplotlib.axis_5\">\n    <g id=\"xtick_17\">\n     <g id=\"line2d_19\"/>\n     <g id=\"text_21\">\n      <!-- 0 -->\n      <g transform=\"translate(45.757159 678.495761) scale(0.16 -0.16)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_18\">\n     <g id=\"line2d_20\"/>\n     <g id=\"text_22\">\n      <!-- 200 -->\n      <g transform=\"translate(85.401368 678.495761) scale(0.16 -0.16)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_19\">\n     <g id=\"line2d_21\"/>\n     <g id=\"text_23\">\n      <!-- 400 -->\n      <g transform=\"translate(135.225577 678.495761) scale(0.16 -0.16)\">\n       <use xlink:href=\"#DejaVuSans-34\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_20\">\n     <g id=\"line2d_22\"/>\n     <g id=\"text_24\">\n      <!-- 600 -->\n      <g transform=\"translate(185.049786 678.495761) scale(0.16 -0.16)\">\n       <use xlink:href=\"#DejaVuSans-36\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_21\">\n     <g id=\"line2d_23\"/>\n     <g id=\"text_25\">\n      <!-- 800 -->\n      <g transform=\"translate(234.873995 678.495761) scale(0.16 -0.16)\">\n       <use xlink:href=\"#DejaVuSans-38\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_22\">\n     <g id=\"line2d_24\"/>\n     <g id=\"text_26\">\n      <!-- 1000 -->\n      <g transform=\"translate(279.608204 678.495761) scale(0.16 -0.16)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_23\">\n     <g id=\"line2d_25\"/>\n     <g id=\"text_27\">\n      <!-- 1200 -->\n      <g transform=\"translate(329.432413 678.495761) scale(0.16 -0.16)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_24\">\n     <g id=\"line2d_26\"/>\n     <g id=\"text_28\">\n      <!-- 1400 -->\n      <g transform=\"translate(379.256622 678.495761) scale(0.16 -0.16)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-34\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_25\">\n     <g id=\"line2d_27\"/>\n     <g id=\"text_29\">\n      <!-- 1600 -->\n      <g transform=\"translate(429.080831 678.495761) scale(0.16 -0.16)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-36\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_30\">\n     <!-- cycle -->\n     <g transform=\"translate(227.909375 701.020136) scale(0.2 -0.2)\">\n      <use xlink:href=\"#DejaVuSans-63\"/>\n      <use xlink:href=\"#DejaVuSans-79\" x=\"54.980469\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"114.160156\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"169.140625\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"196.923828\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_6\">\n    <g id=\"text_31\">\n     <!-- Temperature  param -->\n     <g transform=\"translate(22.396875 668.572432) rotate(-90) scale(0.2 -0.2)\">\n      <use xlink:href=\"#DejaVuSans-54\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"44.083984\"/>\n      <use xlink:href=\"#DejaVuSans-6d\" x=\"105.607422\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"203.019531\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"266.496094\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"328.019531\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"369.132812\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"430.412109\"/>\n      <use xlink:href=\"#DejaVuSans-75\" x=\"469.621094\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"533\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"571.863281\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"633.386719\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"665.173828\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"696.960938\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"760.4375\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"821.716797\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"862.830078\"/>\n      <use xlink:href=\"#DejaVuSans-6d\" x=\"924.109375\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_28\">\n    <path d=\"M 50.847159 654.073043 \nL 52.840127 653.734164 \nL 53.836612 653.862652 \nL 54.085733 653.660201 \nL 54.833096 653.851728 \nL 55.331338 653.803922 \nL 56.078701 654.008818 \nL 57.075185 653.814959 \nL 58.32079 653.678381 \nL 59.566396 653.486757 \nL 60.064638 653.399588 \nL 61.808485 653.038737 \nL 63.303211 652.755234 \nL 64.548817 652.334435 \nL 109.639726 636.210523 \nL 114.123904 634.406967 \nL 128.572925 627.823477 \nL 133.555346 625.566302 \nL 177.151529 605.702789 \nL 179.89186 604.456969 \nL 182.881313 603.074922 \nL 185.870765 601.705012 \nL 196.084728 597.053611 \nL 201.31627 594.680619 \nL 202.561875 594.094859 \nL 216.014412 587.96956 \nL 225.23189 583.792461 \nL 226.726617 583.131635 \nL 235.445853 579.154169 \nL 278.294673 559.687757 \nL 286.515667 555.958075 \nL 291.747209 553.588221 \nL 318.403161 541.492938 \nL 323.385582 539.239846 \nL 326.375035 537.875666 \nL 329.862729 536.320077 \nL 344.062629 529.85269 \nL 349.04505 527.586834 \nL 356.020439 524.431479 \nL 361.750223 521.820735 \nL 389.402659 509.280519 \nL 424.030484 493.574519 \nL 428.514663 491.533415 \nL 429.760268 490.972376 \nL 436.984778 487.702505 \nL 438.728626 486.900576 \nL 443.960168 484.5252 \nL 448.693467 482.386604 \nL 456.665341 478.768696 \nL 456.665341 478.768696 \n\" clip-path=\"url(#pd4f66465f9)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_13\">\n    <path d=\"M 30.55625 662.838261 \nL 30.55625 470.003478 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_14\">\n    <path d=\"M 476.95625 662.838261 \nL 476.95625 470.003478 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_15\">\n    <path d=\"M 30.55625 662.838261 \nL 476.95625 662.838261 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_16\">\n    <path d=\"M 30.55625 470.003478 \nL 476.95625 470.003478 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n  </g>\n  <g id=\"axes_4\">\n   <g id=\"patch_17\">\n    <path d=\"M 30.55625 894.24 \nL 476.95625 894.24 \nL 476.95625 701.405217 \nL 30.55625 701.405217 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g id=\"matplotlib.axis_7\">\n    <g id=\"xtick_26\">\n     <g id=\"line2d_29\"/>\n     <g id=\"text_32\">\n      <!-- 0 -->\n      <g transform=\"translate(45.757159 909.8975) scale(0.16 -0.16)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_27\">\n     <g id=\"line2d_30\"/>\n     <g id=\"text_33\">\n      <!-- 200 -->\n      <g transform=\"translate(88.799216 909.8975) scale(0.16 -0.16)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_28\">\n     <g id=\"line2d_31\"/>\n     <g id=\"text_34\">\n      <!-- 400 -->\n      <g transform=\"translate(142.021272 909.8975) scale(0.16 -0.16)\">\n       <use xlink:href=\"#DejaVuSans-34\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_29\">\n     <g id=\"line2d_32\"/>\n     <g id=\"text_35\">\n      <!-- 600 -->\n      <g transform=\"translate(195.243329 909.8975) scale(0.16 -0.16)\">\n       <use xlink:href=\"#DejaVuSans-36\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_30\">\n     <g id=\"line2d_33\"/>\n     <g id=\"text_36\">\n      <!-- 800 -->\n      <g transform=\"translate(248.465386 909.8975) scale(0.16 -0.16)\">\n       <use xlink:href=\"#DejaVuSans-38\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_31\">\n     <g id=\"line2d_34\"/>\n     <g id=\"text_37\">\n      <!-- 1000 -->\n      <g transform=\"translate(296.597442 909.8975) scale(0.16 -0.16)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_32\">\n     <g id=\"line2d_35\"/>\n     <g id=\"text_38\">\n      <!-- 1200 -->\n      <g transform=\"translate(349.819499 909.8975) scale(0.16 -0.16)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_33\">\n     <g id=\"line2d_36\"/>\n     <g id=\"text_39\">\n      <!-- 1400 -->\n      <g transform=\"translate(403.041556 909.8975) scale(0.16 -0.16)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-34\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_34\">\n     <g id=\"line2d_37\"/>\n     <g id=\"text_40\">\n      <!-- 1600 -->\n      <g transform=\"translate(456.263612 909.8975) scale(0.16 -0.16)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-36\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_41\">\n     <!-- cycle -->\n     <g transform=\"translate(227.909375 932.421875) scale(0.2 -0.2)\">\n      <use xlink:href=\"#DejaVuSans-63\"/>\n      <use xlink:href=\"#DejaVuSans-79\" x=\"54.980469\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"114.160156\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"169.140625\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"196.923828\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_8\">\n    <g id=\"text_42\">\n     <!-- Temperature  param -->\n     <g transform=\"translate(22.396875 899.974171) rotate(-90) scale(0.2 -0.2)\">\n      <use xlink:href=\"#DejaVuSans-54\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"44.083984\"/>\n      <use xlink:href=\"#DejaVuSans-6d\" x=\"105.607422\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"203.019531\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"266.496094\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"328.019531\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"369.132812\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"430.412109\"/>\n      <use xlink:href=\"#DejaVuSans-75\" x=\"469.621094\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"533\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"571.863281\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"633.386719\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"665.173828\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"696.960938\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"760.4375\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"821.716797\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"862.830078\"/>\n      <use xlink:href=\"#DejaVuSans-6d\" x=\"924.109375\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_38\">\n    <path d=\"M 50.847159 885.126116 \nL 51.113269 885.217277 \nL 52.177711 885.112649 \nL 53.774372 885.154591 \nL 54.040482 885.296033 \nL 58.032137 885.329724 \nL 61.22546 884.825654 \nL 62.023791 884.664186 \nL 65.217114 883.907425 \nL 117.90695 864.836297 \nL 138.663553 855.359757 \nL 151.702956 849.40829 \nL 256.550408 801.518603 \nL 258.14707 800.791261 \nL 260.542062 799.674057 \nL 262.937055 798.597525 \nL 264.001496 798.115558 \nL 265.065937 797.623009 \nL 290.612524 785.922397 \nL 292.209186 785.202439 \nL 319.086325 772.836074 \nL 323.87631 770.625172 \nL 348.624566 759.385728 \nL 349.422897 759.037188 \nL 351.019558 758.279691 \nL 352.88233 757.448128 \nL 354.212882 756.806403 \nL 356.341764 755.840965 \nL 368.316727 750.39448 \nL 369.115058 750.04839 \nL 370.179499 749.520434 \nL 370.97783 749.187056 \nL 372.308381 748.555528 \nL 377.098366 746.402028 \nL 377.896697 745.990503 \nL 384.549454 742.997256 \nL 385.880006 742.359186 \nL 410.628262 731.127222 \nL 411.426593 730.760834 \nL 425.796548 724.209164 \nL 426.594879 723.845984 \nL 452.673687 711.925347 \nL 456.665341 710.170435 \nL 456.665341 710.170435 \n\" clip-path=\"url(#p56224f4b78)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_18\">\n    <path d=\"M 30.55625 894.24 \nL 30.55625 701.405217 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_19\">\n    <path d=\"M 476.95625 894.24 \nL 476.95625 701.405217 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_20\">\n    <path d=\"M 30.55625 894.24 \nL 476.95625 894.24 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_21\">\n    <path d=\"M 30.55625 701.405217 \nL 476.95625 701.405217 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p909d86f1f6\">\n   <rect x=\"30.55625\" y=\"7.2\" width=\"446.4\" height=\"192.834783\"/>\n  </clipPath>\n  <clipPath id=\"p0bb4cf4a46\">\n   <rect x=\"30.55625\" y=\"238.601739\" width=\"446.4\" height=\"192.834783\"/>\n  </clipPath>\n  <clipPath id=\"pd4f66465f9\">\n   <rect x=\"30.55625\" y=\"470.003478\" width=\"446.4\" height=\"192.834783\"/>\n  </clipPath>\n  <clipPath id=\"p56224f4b78\">\n   <rect x=\"30.55625\" y=\"701.405217\" width=\"446.4\" height=\"192.834783\"/>\n  </clipPath>\n </defs>\n</svg>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T06:37:38.970602Z",
     "start_time": "2025-03-31T06:37:38.958782Z"
    }
   },
   "cell_type": "code",
   "source": [
    "path='D:/Pywork/CNN_ATTENTION_PINN/new/results/hust/'\n",
    "for i in range(4):\n",
    "    e=lists[i][1]\n",
    "    s=lists[i][4]\n",
    "    np.savez(path+f'result{i}.npz',array1=e,array2=s)\n",
    "    \n",
    "    "
   ],
   "id": "fe337a30412a4c5d",
   "outputs": [],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d4b59d2be8ced8fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T03:57:52.416546Z",
     "start_time": "2025-03-02T03:57:52.405032Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.023920438949407877\n",
      "0.023711104812099242\n",
      "0.02149544575249883\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    real,pred=test_results[i][0],test_results[i][1]\n",
    "    rmse=evaluation(real,pred)\n",
    "    print(rmse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "work",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
